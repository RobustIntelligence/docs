{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **RI Generative Stress Test Falcon-40b-instruct Internal**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll run RIME's Generative AI Stress Testing on Falcon-40b-instruct model to demonstrate how RIME can be used with generative models (https://huggingface.co/tiiuae/falcon-40b-instruct)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Install Dependencies, Import Libraries and Download Data**\n",
    "Run the cell below to install libraries to receive data, install our SDK, and load analysis libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure to set your virtual env in the notebook kernel to one that has the latest rime-sdk!\n",
    "!pip install rime-sdk &> /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from rime_sdk import Client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Establish the RIME Client**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_TOKEN = '' # PASTE API_KEY \n",
    "CLUSTER_URL = '' # PASTE DEDICATED DOMAIN OF RIME SERVICE (eg: rime.stable.rbst.io)\n",
    "AGENT_ID = '' # PASTE AGENT_ID IF USING AN AGENT THAT IS NOT THE DEFAULT\n",
    "\n",
    "client = Client(CLUSTER_URL, API_TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Create a New Project** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "description = (\n",
    "    \"Run Generative Stress Testing on a\"\n",
    "    \" generative model and dataset. Demonstration uses\"\n",
    "    \" a dataset composed of short scenarios that are each\"\n",
    "    \" identifed by title and characterized by context,\"\n",
    "    \" a question, an answer, and a prompt.\"\n",
    ")\n",
    "project = client.create_project(\n",
    "    name=\"Falcon-40b-instruct\", \n",
    "    description=description, \n",
    "    model_task=\"MODEL_TASK_QUESTION_ANSWERING\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Register and Upload the Model + Dataset**\n",
    "This model path uses a Basten hosted model. Please be mindful of running tests using Baseten's models and checking costs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_path = \"falcon_40b_instruct\"\n",
    "\n",
    "model_s3_dir = client.upload_directory(\n",
    "    Path('../../../python/rime/test_data/models/question_answering'), upload_path=upload_path\n",
    ")\n",
    "# This file is stored https://github.com/RobustIntelligence/rime/blob/master/python/rime/test_data/models/question_answering/falcon_40b_instruct.py\n",
    "model_s3_path = model_s3_dir + \"/falcon_40b_instruct.py\"\n",
    "\n",
    "eval_s3_path = client.upload_file(\n",
    "    Path('../../../python/rime/test_data/data/question_answering/squad_v2_test_with_labels.json'), upload_path=upload_path\n",
    ")\n",
    "\n",
    "fact_sheet_path = client.upload_file(\n",
    "    Path('../../../python/rime/test_data/data/question_answering/individual_test_artifacts/fact_sheet.txt'), upload_path=upload_path\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the data and model are uploaded to S3, we can register them to RIME. Once they're registered, we can refer to these resources using their RIME-generated ID's. We also need to obtain an integration ID from the workspace, which is then used to register the model and aid in stress test configuration. We need to provide an OpenAI API key and Baseten API key to call the model (the model is hosted on Baseten). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "dt = str(datetime.now())\n",
    "\n",
    "integration_id = client.create_integration(\n",
    "    workspace_id=\"\", # PASTE WORKSPACE ID FROM INFO BUTTON ON WORKSPACE OVERVIEW PAGE\n",
    "    name=f\"GAI_walkthrough_test{dt}\",\n",
    "    integration_type=\"INTEGRATION_TYPE_CUSTOM\", \n",
    "    integration_schema=[\n",
    "        {\n",
    "            \"name\": \"OPENAI_API_KEY\",\n",
    "            \"sensitivity\": \"VARIABLE_SENSITIVITY_WORKSPACE_SECRET\",\n",
    "            \"value\": \"\", # FILL IN YOUR OPENAI API KEY HERE\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"BASETEN_API_KEY\",\n",
    "            \"sensitivity\": \"VARIABLE_SENSITIVITY_WORKSPACE_SECRET\",\n",
    "            \"value\": \"\", # FILL IN YOUR BASETEN API KEY HERE.\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Note: models and datasets need to have unique names.\n",
    "model_id = project.register_model(\n",
    "    name=f\"model_test{dt}\",\n",
    "    model_config= {\n",
    "        \"generative_language_model\": {\n",
    "            \"model_path\": model_s3_path,\n",
    "            #\"system_prompt\": \"\", This model.py does not support system prompt\n",
    "        },\n",
    "    },    \n",
    "    model_endpoint_integration_id=integration_id,\n",
    "    skip_validation=True\n",
    ")\n",
    "\n",
    "data_params = {\n",
    "    \"label_col\": \"answer\",\n",
    "    \"prompt_col\": \"prompt\",\n",
    "    \"sample\": True,\n",
    "    \"text_features\": [\n",
    "        \"context\",\n",
    "        \"question\"]\n",
    "}\n",
    "eval_dataset_id = project.register_dataset(\n",
    "    name=f\"eval_dataset_{dt}\",\n",
    "    data_config={\n",
    "        \"connection_info\": {\"data_file\": {\"path\": eval_s3_path}},\n",
    "        \"data_params\": data_params\n",
    "    }\n",
    ")\n",
    "\n",
    "test_suite_config = {\n",
    "    \"individual_tests_config\": {\n",
    "        \"stereotypical_sentence_fill\": {\"run\": True},\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [IMPORTANT MANUAL STEP] Call the model before starting the stress test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model scales to 0 in Baseten (https://app.baseten.co/models/b0doYgB/versions/wpj18zw/overview) when it is not being used, so in order to start running stress tests - we first need to make sure the model is scaled up! You also need to input your `baseten_api_key` if it is not set as an ENV var already.\n",
    "\n",
    "Please check costs in Baseten and do not run this notebook unnecessarily - every run costs us!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"../../../python/rime/test_data/models/question_answering/falcon_40b_instruct.py\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Running a Generative Stress Test**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Generative Stress Test allows you to test your data and model before deployment. They are a comprehensive suite of hundreds of tests that automatically identify implicit assumptions and weaknesses of pre-production models. Each stress test is run on a single model and displays corresponding results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a sample configuration of how to setup and run a RIME Generative Stress Test. This configuration specifies relevant metadata for our dataset and model to run the stress test, along with test categories that are most useful for this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generative_stress_test_config = {\n",
    "    \"run_name\":\"Falcon-40b-instruct\", \n",
    "    \"model_id\": model_id,\n",
    "    \"data_info\": {\"eval_dataset_id\": eval_dataset_id},\n",
    "    \"run_time_info\": {\"explicit_errors\": False},\n",
    "    # For the full model profile, comment out the following line.\n",
    "    \"profiling_config\": {\"model_profiling\": {\"nrows_for_summary\": "20"}},\n",
    "    \"test_suite_config\": test_suite_config,\n",
    "    \"categories\": [\n",
    "        \"TEST_CATEGORY_TYPE_ADVERSARIAL\",\n",
    "        \"TEST_CATEGORY_TYPE_SUBSET_PERFORMANCE\",\n",
    "        \"TEST_CATEGORY_TYPE_TRANSFORMATIONS\",\n",
    "        \"TEST_CATEGORY_TYPE_MODEL_ALIGNMENT\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "stress_job = client.start_stress_test(\n",
    "    test_run_config=generative_stress_test_config,\n",
    "    project_id=project.project_id\n",
    ")\n",
    "stress_job.get_status(verbose=True, wait_until_finish=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_run = stress_job.get_test_run()\n",
    "test_run"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

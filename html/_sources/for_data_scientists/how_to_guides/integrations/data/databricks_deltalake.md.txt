# Databricks Delta Lake

RIME supports loading data directly from Databricks Delta Lake. Files no longer require copying, either locally or to S3. Configure
Databricks Delta Lake [using the UI.](../../../../for_admins/data-integrations.md)

In order to configure the Databricks Delta Lake, you need to enter the following information:

* Connection Details - Server Hostname, HTTP Path
+ Databricks [Personal Access Token](https://docs.databricks.com/dev-tools/auth.html#pat)

**Retrieving connection details for Databricks Delta Lake** 

This procedure presumes you are logged in to Delta Lake.

1.  Click compute icon in the sidebar. 
2.  Choose a cluster to connect to. 
3.  Navigate to Advanced Options. 
4.  Click on the JDBC/ODBC tab. 
5.  Copy the above connection details.

After configuring the data integration, use the underlying delta tables
to run stress tests and continuous tests. More information on defining 
the configurations is available in the 
[Data Configuration](../../../reference/data_source.md) section.
Additionally, information about how to integrate the delta tables into your
Scheduled CT workflow can be found in [Scheduled CT Configuration](../../../how_to_guides/common_use_cases/scheduled_ct_configuration.md).

1.  Log in to a Databricks Delta Lake instance.
2.  Click the compute icon in the sidebar and connect to a cluster.
3.  In Advanced Options, click the *JDBC/ODBC* tab.
    >   The connection details appear.

Note the connection details for future use.

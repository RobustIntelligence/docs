# Google AutoML

In order to connect RIME to a deployed Google AutoML model, you can copy the below Python snippet into a Python model. Then go through that snippet and replace all the TODOs with neccessary credentials/endpoints.

Once that is done, you can specify that model file when [configuring your model source](/for_data_scientists/reference/tabular/model_source.md).

```python
"""Template for how you can use RIME for a model hosted on Google Cloud AutoML.

We expect this file to contain a `predict_dict` function that takes in a mapping from
feature name to feature value. This corresponds to one row in the dataset. This
method should return a score between 0 and 1.


This specific file implements this assuming that 1) your model is hosted
on an Google cloud, and 2), that your machine is authenticated with Google Cloud,
and 3) that you have the AutoML client library (google-cloud-automl) installed.

"""
import json
import pandas as pd
from google.cloud import automl_v1beta1 as automl


# Step 1: Define endpoint variables.
PROJECT_ID = 'TODO: project ID'
COMPUTE_REGION = 'TODO: region'
MODEL_DISPLAY_NAME = 'TODO: display_name'

# Step 2: Instantiate automl client.
# NOTE: By default we assume that the path to your gcloud credentials are stored
# under the environment variable GOOGLE_APPLICATION_CREDENTIALS.
# If you wish to specify the path yourself, please use the commented code instead
# of the default code.
# For more info, see: https://cloud.google.com/docs/authentication/getting-started
client = automl.TablesClient(project=PROJECT_ID, region=COMPUTE_REGION)

# NOTE: uncomment below to manually specify path to credentials file.
# from google.oauth2 import service_account
# credentials = service_account.Credentials.from_service_account_file(
#     '/path/to/key.json'
# )
# client = automl.TablesClient(
#     project=PROJECT_ID, region=COMPUTE_REGION, credentials=credentials
# )


# Step 3: Implement the below function that should be applied to a row of data 
# (in dictionary form), including any requisite preprocessing logic.
# By default, we assume that after preprocessing, the input is then sent to the
# model endpoint through `client.predict`, but feel free to edit/add/remove
# functions as you wish.


def custom_preprocessing(x: dict):
    # TODO: fill out preprocessing logic
    return x


def predict_dict(x: dict):
    x = custom_preprocessing(x)
    response = client.predict(
        model_display_name=MODEL_DISPLAY_NAME, inputs=x
    )
    result = response.payload[0]
    # NOTE: this only for binary classification
    return 1 - int(result.tables.value) - result.tables.score

```
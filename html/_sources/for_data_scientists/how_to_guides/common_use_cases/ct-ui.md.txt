# Continuous Tests

A continuous test evaluates a machine learning model's resilience with regards to a specific
vulnerability.

## Creating a new Continuous Test from the SDK

This procedure presumes a model is already loaded into RIME and that all commands are issued in a Python environment.

1.  (When a suitable [project](projects.md) does not already exist) Create a project 
    using the following [SDK command](../../../python_library/python-sdk.rst).
    >   ```
    >   project = rime_client.create_project(
    >       name="foo", description="bar", model_task="MODEL_TASK_BINARY_CLASSIFICATION"`
    >   )
    >   ```
2.  Register a reference dataset.
    >   ```
    >   reference_id = project.register_dataset(
    >       name=DATASET_NAME,
    >       data_params={
    >           "connection_info": {"data_file": {"path": FILE_PATH}},
    >           "data_params": {"label_col": LABEL_COL},
    >       },
    >       integration_id=INTEGRATION_ID,
    >   )
    >   ```

    >   The SDK returns the ID of the reference dataset.
3.  Register an evaluation dataset.
    >   ```
    >   evaluation_id = project.register_dataset(
    >       name="bar", data_config=dict
    >   )
    >   ```

    >   The SDK returns the ID of the evaluation dataset.
4.  Register a model.
    >   ```
    >   model = project.register_model(
    >       name="baz"
    >   )
    >   ```

    >   The SDK returns the model ID.
5.  Register a prediction set.
    >   ```
    >   prediction = rime_project.register_predictions(
    >   dataset_id=DATASET_ID,
    >   model_id=MODEL_ID,
    >   pred_config={
    >       "connection_info": {
    >           "delta_lake": {
    >               # Unix timestamp equivalent to 02/08/2023
    >               "start_time": 1675922943,
    >               # Unix timestamp equivalent to 03/08/2023
    >               "end_time": 1678342145,
    >               "table_name": TABLE_NAME,
    >               "time_col": TIME_COL,
    >           },
    >       },
    >       "pred_params": {"pred_col": PREDS},
    >   },
    >   )
    >   ```

    >   The SDK returns the prediction set ID.
6.  Create a new Continous Test in the project.
    >   ```
    >   project.create_firewall(
    >       model_id="model", ref_data_id="foo",bin_size=timedelta(hours=3)
    >   )
    >   ```
7.  Issue the following command to start the Continuous Test, specifying the configuration
    created in the previous step and the unique ID of the project that contains the
    Continuous Test.
    >   ```
    >   continuous_test = firewall.start_continuous_test(
    >      eval_data_id="bar", override_existing_bins=False,
    >   )
    >   ```

<!-- ## Creating a new Continuous Test from the web UI

1.  Sign in to an RI Platform instance.  
    >   The Workspaces page appears.
2.  Select a workspace.  
    >   The workspace summary page appears, listing the projects in that workspace.
3.  Select a project.  
    >   The project summary page appears.
4.  In the left navigation bar, click *Continuous Testing*.
    >   The Continous Testing Overview page appears.
5.  Click *Start Continuous Testing*.
    >   The Continuous Testing wizard appears.
6.  Select a set of tests.
    >   | Test category | Test |
    >   |---------------|------|
    >   | Operational risks | Overall performance |
    >   |   | Subset performance |
    >   |   | Drift (continuous testing focus) |
    >   |   | Transformations (stress testing focus) |
    >   |   | Abnormal inputs (continuous testing focus) |
    >   | Security risks | Adversarial |
    >   | Fairness risks | Compliance and fairness |
7.  Select an overall test sensitivity level.
8.  Choose a model to test from the list of registered models or register a new model.
9. (When using a registered model) Select the model from the *Select Model* drop-down.
10. (When registering a new model) Choose whether to upload a model file or to add a model from an online registry.
11. (When uploading a new model) Type a name and tags for the model.
12. (When uploading a new model) Drag a `pkl` or `py` model file to the wizard or click *Select File* to browse the file system.
13. (When registering a new model from a registry) Type the name of the registry, the URI or file path to the model in the registry, and the registry secret.
14. Click *Next*.
15. Choose whether to use a registered reference dataset or a dataset from a connection.
16. (Using a registered reference dataset) Type the name of the registered dataset.
17. (Using a reference dataset from a connection) Type a connection name, a table name, a timestamp column, and a label column
18. (Using a reference dataset from a connection) (Optional) Activate the *Predictions (optional)* toggle and enter a connection name, table name, optional timestamp column, and prediction column.
19. Click *Next*.
20. Select a bin size from the *Bin Size* drop-down.
21. Select a type of reference window from the *Reference Window Type* drop-down.
22. (When the reference window type is Rolling) Select number of bins for the rolling reference window.
23. In *Data Source*, type the name of the evaluation dataset.
24. In *Table Name*, type the name of a table in the evaluation dataset.
25. (Optional) Choose a timestamp column in the specified table from the *Timestamp Column (optional)* drop-down.
26. Type a column name in *Label Column*.
27. (Optional) Activate the *Predictions (optional)* toggle and enter a connection name, table name, optional timestamp column name, and prediction column name.
28. Click *Next*.

The wizard closes and the new Continuous Test begins initial processing. -->

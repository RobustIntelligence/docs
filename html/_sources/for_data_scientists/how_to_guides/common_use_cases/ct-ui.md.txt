# Continuous Tests

A continuous test evaluates a machine learning model's resilience with regards to a specific
vulnerability.

## Creating a new Continuous Test

1.  Sign in to an RI Platform instance.  
    >   The Workspaces page appears.
2.  Select a workspace.  
    >   The workspace summary page appears, listing the projects in that workspace.
3.  Select a project.  
    >   The project summary page appears.
4.  In the left navigation bar, click *Continuous Testing*.
    >   The Continous Testing Overview page appears.
5.  Click *Start Continuous Testing*.
    >   The Continuous Testing wizard appears.
6.  Select a set of tests.
    >   | Test category | Test |
    >   |---------------|------|
    >   | Operational risks | Overall performance |
    >   |   | Subset performance |
    >   |   | Drift (continuous testing focus) |
    >   |   | Transformations (stress testing focus) |
    >   |   | Abnormal inputs (continuous testing focus) |
    >   | Security risks | Adversarial |
    >   | Fairness risks | Compliance and fairness |
7.  Select an overall test sensitivity level.
8.  Choose a model to test from the list of registered models or register a new model.
9. (When using a registered model) Select the model from the *Select Model* drop-down.
10. (When registering a new model) Choose whether to upload a model file or to add a model from an online registry.
11. (When uploading a new model) Type a name and tags for the model.
12. (When uploading a new model) Drag a `pkl` or `py` model file to the wizard or click *Select File* to browse the file system.
13. (When registering a new model from a registry) Type the name of the registry, the URI or file path to the model in the registry, and the registry secret.
14. Click *Next*.
15. Choose whether to use a registered reference dataset or a dataset from a connection.
16. (Using a registered reference dataset) Type the name of the registered dataset.
17. (Using a reference dataset from a connection) Type a connection name, a table name, a timestamp column, and a label column
18. (Using a reference dataset from a connection) (Optional) Activate the *Predictions (optional)* toggle and enter a connection name, table name, optional timestamp column, and prediction column.
19. Click *Next*.
20. Select a bin size from the *Bin Size* drop-down.
21. Select a type of reference window from the *Reference Window Type* drop-down.
22. (When the reference window type is Rolling) Select number of bins for the rolling reference window.
23. In *Data Source*, type the name of the evaluation dataset.
24. In *Table Name*, type the name of a table in the evaluation dataset.
25. (Optional) Choose a timestamp column in the specified table from the *Timestamp Column (optional)* drop-down.
26. Type a column name in *Label Column*.
27. (Optional) Activate the *Predictions (optional)* toggle and enter a connection name, table name, optional timestamp column name, and prediction column name.
28. Click *Next*.

The wizard closes and the new Continuous Test begins initial processing.
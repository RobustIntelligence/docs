# Continuous Tests

A continuous test evaluates a machine learning model's resilience with regards to a specific
vulnerability.

## Creating a new Continuous Test from the SDK

This procedure presumes a model is already [loaded](../../../python_library/how_to_guides/rime_data_model_setup.md) into RIME and that all commands are issued in a Python environment.

1.  (When a suitable [project](projects.md) does not already exist) Create a project 
    using the following [SDK command](../../../python_library/python-sdk.rst).
    >   `project = rime_client.create_project(`
    >       `name="foo", description="bar", model_task="Binary Classification"`
    >   `)`
2.  Register a reference dataset.
    >   `reference = rime_project.register_dataset(`
    >       `name="foo",data_config=dict`
    >   `)`

    >   The SDK returns the ID of the reference dataset.
3.  Register an evaluation dataset.
    >   `evaluation = rime_project.register_dataset(`
    >       `name="bar",data_config=dict`
    >   `)`

    >   The SDK returns the ID of the evaluation dataset.
4.  Register a model.
    >   `model = rime_project.register_model(`
    >       `name="baz"`
    >   `)`

    >   The SDK returns the model ID.
5.  Create a [test run configuration](../../reference/tabular/tests.md) that uses the 
    registered reference and evaluation datasets and the model, specifying a name and
    model task in addition to the IDs of the datasets and model registered earlier in
    this procedure.
    >   `config = {`
    >       `"data_info": {"ref_dataset_id": "foo", "eval_dataset_id": "bar"},`
    >       `"model_id": model_uuid,`
    >       `"run_name": "My Stress Test Run",`
    >       `"model_task": "Binary Classification",`
    >   `}`
6.  Create a new Continous Test in the project.
    >   `project.create_firewall(`
    >       `model_id:"model", ref_data_id:"foo",bin_size:timedelta(hours=3)`
    >   `)`
7.  Issue the following command to start the Continuous Test, specifying the configuration
    created in the previous step and the unique ID of the project that contains the
    Continuous Test.
    >   `continuous_test = project.start_continuous_test(`
    >       `eval_data_id:="bar", override_existing_bins:False,`
    >   `)`



<!-- ## Creating a new Continuous Test

1.  Sign in to an RI Platform instance.  
    >   The Workspaces page appears.
2.  Select a workspace.  
    >   The workspace summary page appears, listing the projects in that workspace.
3.  Select a project.  
    >   The project summary page appears.
4.  In the left navigation bar, click *Continuous Testing*.
    >   The Continous Testing Overview page appears.
5.  Click *Start Continuous Testing*.
    >   The Continuous Testing wizard appears.
6.  Select a set of tests.
    >   | Test category | Test |
    >   |---------------|------|
    >   | Operational risks | Overall performance |
    >   |   | Subset performance |
    >   |   | Drift (continuous testing focus) |
    >   |   | Transformations (stress testing focus) |
    >   |   | Abnormal inputs (continuous testing focus) |
    >   | Security risks | Adversarial |
    >   | Fairness risks | Compliance and fairness |
7.  Select an overall test sensitivity level.
8.  Choose a model to test from the list of registered models or register a new model.
9. (When using a registered model) Select the model from the *Select Model* drop-down.
10. (When registering a new model) Choose whether to upload a model file or to add a model from an online registry.
11. (When uploading a new model) Type a name and tags for the model.
12. (When uploading a new model) Drag a `pkl` or `py` model file to the wizard or click *Select File* to browse the file system.
13. (When registering a new model from a registry) Type the name of the registry, the URI or file path to the model in the registry, and the registry secret.
14. Click *Next*.
15. Choose whether to use a registered reference dataset or a dataset from a connection.
16. (Using a registered reference dataset) Type the name of the registered dataset.
17. (Using a reference dataset from a connection) Type a connection name, a table name, a timestamp column, and a label column
18. (Using a reference dataset from a connection) (Optional) Activate the *Predictions (optional)* toggle and enter a connection name, table name, optional timestamp column, and prediction column.
19. Click *Next*.
20. Select a bin size from the *Bin Size* drop-down.
21. Select a type of reference window from the *Reference Window Type* drop-down.
22. (When the reference window type is Rolling) Select number of bins for the rolling reference window.
23. In *Data Source*, type the name of the evaluation dataset.
24. In *Table Name*, type the name of a table in the evaluation dataset.
25. (Optional) Choose a timestamp column in the specified table from the *Timestamp Column (optional)* drop-down.
26. Type a column name in *Label Column*.
27. (Optional) Activate the *Predictions (optional)* toggle and enter a connection name, table name, optional timestamp column name, and prediction column name.
28. Click *Next*.

The wizard closes and the new Continuous Test begins initial processing. -->
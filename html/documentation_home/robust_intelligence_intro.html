<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>What is Robust Intelligence? &mdash; Robust Intelligence  documentation</title>
      <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../_static/copybutton.css" type="text/css" />
      <link rel="stylesheet" href="../_static/tabs.css" type="text/css" />
      <link rel="stylesheet" href="https://cdn.datatables.net/v/dt/dt-1.13.1/sb-1.4.0/datatables.min.css" type="text/css" />
      <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/sphinx_highlight.js"></script>
        <script src="../_static/clipboard.min.js"></script>
        <script src="../_static/copybutton.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script src="../_static/main.js"></script>
        <script src="https://cdn.datatables.net/v/dt/dt-1.13.1/sb-1.4.0/datatables.min.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Get Started" href="get_started.html" />
    <link rel="prev" title="Welcome to Robust Intelligence!" href="../index.html" />
<link href="../_static/style.css" rel="stylesheet" type="text/css">

</head>

<body class="wy-body-for-nav">
<div class="ge_header no-print">
    <a id="header-logo" href="../index.html">
        <img src="../_static/images/header-logo.png" alt="logo" />
    </a>
</div>


  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            Robust Intelligence
          </a>
              <div class="version">
                2.3.0
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Documentation Home</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">What is Robust Intelligence?</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#what-is-ai-risk">What is AI Risk?</a></li>
<li class="toctree-l2"><a class="reference internal" href="#why-we-test">Why We Test</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#why-we-run-stress-tests">Why We Run Stress Tests</a></li>
<li class="toctree-l3"><a class="reference internal" href="#why-we-run-continuous-tests">Why We Run Continuous Tests</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#risk-testing-built-into-your-ai-pipeline">Risk Testing Built into Your AI Pipeline</a></li>
<li class="toctree-l2"><a class="reference internal" href="#measuring-ai-risk">Measuring AI Risk</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#key-machine-learning-tasks-covered">Key Machine Learning Tasks Covered</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#tabular">Tabular</a></li>
<li class="toctree-l4"><a class="reference internal" href="#natural-language-processing-nlp">Natural Language Processing (NLP)</a></li>
<li class="toctree-l4"><a class="reference internal" href="#computer-vision-cv">Computer Vision (CV)</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#stress-testing">Stress Testing</a></li>
<li class="toctree-l2"><a class="reference internal" href="#continuous-testing">Continuous Testing</a></li>
<li class="toctree-l2"><a class="reference internal" href="#robust-intelligence-inputs">Robust Intelligence Inputs</a></li>
<li class="toctree-l2"><a class="reference internal" href="#ai-compliance-management-model-cards">AI Compliance Management - Model Cards</a></li>
<li class="toctree-l2"><a class="reference internal" href="#workspace-overview">Workspace Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="#related-topics">Related Topics</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="get_started.html">Get Started</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Testing and Monitoring</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../testing_and_monitoring/creating_projects.html">Creating Projects</a></li>
<li class="toctree-l1"><a class="reference internal" href="../testing_and_monitoring/preparing_your_models_and_datasets.html">Preparing Your Models and Datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="../testing_and_monitoring/validating_models.html">Validate Models with Stress Tests</a></li>
<li class="toctree-l1"><a class="reference internal" href="../testing_and_monitoring/monitoring_models.html">Monitor Models with Continuous Tests</a></li>
<li class="toctree-l1"><a class="reference internal" href="../testing_and_monitoring/configuring_test_runs.html">Configuring your Test Runs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../testing_and_monitoring/querying_results.html">Querying Test Run Results</a></li>
<li class="toctree-l1"><a class="reference internal" href="../testing_and_monitoring/notifications_and_alerts.html">Notifications and Alerts</a></li>
<li class="toctree-l1"><a class="reference internal" href="../testing_and_monitoring/model_governance.html">Managing Model Governance</a></li>
<li class="toctree-l1"><a class="reference internal" href="../testing_and_monitoring/integrating_mlops.html">Integrating with MLOps</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Administration</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../administration/organization_administration.html">Organization Administration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../administration/workspace_configuration.html">Workspace Configuration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../administration/security_and_compliance.html">Security and Compliance</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Deployment</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../deployment/index.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../deployment/requirements.html">Requirements</a></li>
<li class="toctree-l1"><a class="reference internal" href="../deployment/installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../deployment/upgrade.html">Upgrade</a></li>
<li class="toctree-l1"><a class="reference internal" href="../deployment/faq.html">FAQ</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../reference/model_tests_reference.html">Model Tests</a></li>
<li class="toctree-l1"><a class="reference internal" href="../reference/python-sdk.html">Python SDK Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../reference/troubleshooting.html">Troubleshooting Home</a></li>
<li class="toctree-l1"><a class="reference internal" href="../reference/release_notes.html">Release Notes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../reference/api_changelog.html">API Changelog</a></li>
<li class="toctree-l1"><a class="reference internal" href="../reference/legal.html">Robust Intelligence Terms and Conditions</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Robust Intelligence</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">What is Robust Intelligence?</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="what-is-robust-intelligence">
<h1>What is Robust Intelligence?<a class="headerlink" href="#what-is-robust-intelligence" title="Permalink to this heading"></a></h1>
<p>Welcome to Robust Intelligence, the solution for maintaining AI integrity. The platform helps you identify and eliminate the risks inherent to production AI by integrating into your AI pipeline.</p>
<section id="what-is-ai-risk">
<h2>What is AI Risk?<a class="headerlink" href="#what-is-ai-risk" title="Permalink to this heading"></a></h2>
<p>AI risk refers to the potential negative consequences of using AI models in production, including operational, ethical, and security risks.</p>
<ul class="simple">
<li><p><strong>Security risks</strong> occur when models are vulnerable to adversarial
actors who try to exploit or compromise a machine learning model’s
performance. Proprietary and third-party models may be susceptible
to data leakage and adversarial attacks, including system breaches,
model evasion, and theft. All models must be regularly screened
before and during use to protect against a wide array of evolving
vulnerabilities and threats.</p></li>
<li><p><strong>Ethical risks</strong> stem from model behavior that violates norms,
laws, regulations, or other governance standards. AI models can have
or develop a variety of ethical issues, including bias, fairness,
and use of offensive language. This can lead to inequality,
reputational damage, and lawsuits.</p></li>
<li><p><strong>Operational risks</strong> can arise from subpar model performance.
Changes in data can lead to model failures including performance
drift, corruption, and broken data pipelines. These failures can
affect an organization’s operations in terms of lost revenue, lost
trust, damage to the organization’s reputation, and resource
constraints.</p></li>
</ul>
</section>
<section id="why-we-test">
<h2>Why We Test<a class="headerlink" href="#why-we-test" title="Permalink to this heading"></a></h2>
<section id="why-we-run-stress-tests">
<h3>Why We Run Stress Tests<a class="headerlink" href="#why-we-run-stress-tests" title="Permalink to this heading"></a></h3>
<p><a class="reference internal" href="../testing_and_monitoring/validating_models.html"><span class="std std-doc">Stress Testing</span></a>
measures the robustness of your AI model before you deploy it. Test
results identify security, ethical, and operational risks and
weaknesses in your model and provide you with insights on how to
improve it before deployment.</p>
</section>
<section id="why-we-run-continuous-tests">
<h3>Why We Run Continuous Tests<a class="headerlink" href="#why-we-run-continuous-tests" title="Permalink to this heading"></a></h3>
<p><a class="reference internal" href="../testing_and_monitoring/monitoring_models.html"><span class="std std-doc">Continuous Testing</span></a>
monitors AI models that are deployed in production in order to detect
when vulnerabilities or failures emerge, such as data drift or
inability to withstand adversarial attacks.</p>
</section>
</section>
<section id="risk-testing-built-into-your-ai-pipeline">
<h2>Risk Testing Built into Your AI Pipeline<a class="headerlink" href="#risk-testing-built-into-your-ai-pipeline" title="Permalink to this heading"></a></h2>
<p>Robust Intelligence allows you to test and monitor your models for
security, ethical, and operational risk by integrating into the
following phases of your model development and deployment pipeline:</p>
<ul class="simple">
<li><p>During model development,
<a class="reference internal" href="../testing_and_monitoring/validating_models.html"><span class="std std-doc">AI Stress Testing</span></a>
measures the robustness of your model by running dozens of
pre-configured tests. Each test checks the model’s vulnerability to
a specific form of potential failure in production.</p></li>
<li><p>Once models are deployed into production,
<a class="reference internal" href="../testing_and_monitoring/monitoring_models.html"><span class="std std-doc">AI Continuous Testing</span></a>
monitors your model and alerts you to issues such as data drift and
detected adversarial attacks.</p></li>
</ul>
</section>
<section id="measuring-ai-risk">
<h2>Measuring AI Risk<a class="headerlink" href="#measuring-ai-risk" title="Permalink to this heading"></a></h2>
<p>In modern engineering organizations, data scientists and machine learning engineers typically invest a significant amount of effort into the development stage of the model life cycle, which includes tasks such as data ingestion and cleaning, feature extraction, and model training. During this stage, models are evaluated mainly based on their performance on clean test data.</p>
<p>While these metrics may be useful in controlled development environments, deploying models in production introduces a new set of challenges and risks that are often overlooked. Once a model is deployed, data scientists lose control over how the model is used and how data is passed into it. Moreover, they have no oversight over the data pipelines that incorporate the model. Even when the model is used correctly, the real world can change, leading to issues like distributional shifts in production data, which can silently degrade model performance.
These risks can manifest in several ways, such as operational, ethical, and security risks. Operational risks arise from subpar model performance, which may occur due to factors such as data drift or other distributional shifts in the production environment. Ethical risks occur when model behavior violates regulatory or governance standards, which may lead to legal or reputational harm for the organization. Finally, security risks arise when models are vulnerable to adversarial actors who can exploit or compromise the model’s performance.</p>
<p>To mitigate these risks, it’s crucial to have tools like Robust Intelligence that allow you to test and monitor models continuously throughout their lifecycle, from development to deployment. This ensures that you catch any issues as they arise and can take corrective action before they cause significant problems.</p>
<img src="../_static/images/adopting_ai_risk.png">
<section id="key-machine-learning-tasks-covered">
<h3>Key Machine Learning Tasks Covered<a class="headerlink" href="#key-machine-learning-tasks-covered" title="Permalink to this heading"></a></h3>
<p>Robust Intelligence provides model testing across the following broad task categories:</p>
<section id="tabular">
<h4>Tabular<a class="headerlink" href="#tabular" title="Permalink to this heading"></a></h4>
<ul class="simple">
<li><p>Binary Classification</p></li>
<li><p>Multiclass Classification</p></li>
<li><p>Regression</p></li>
<li><p>Learning to Rank</p></li>
</ul>
</section>
<section id="natural-language-processing-nlp">
<h4>Natural Language Processing (NLP)<a class="headerlink" href="#natural-language-processing-nlp" title="Permalink to this heading"></a></h4>
<ul class="simple">
<li><p>Text Classification</p></li>
<li><p>Named Entity Recognition</p></li>
<li><p>Natural Language Inference</p></li>
<li><p>Fill-Mask Modeling</p></li>
</ul>
</section>
<section id="computer-vision-cv">
<h4>Computer Vision (CV)<a class="headerlink" href="#computer-vision-cv" title="Permalink to this heading"></a></h4>
<ul class="simple">
<li><p>Image Classification</p></li>
<li><p>Object Detection</p></li>
</ul>
</section>
</section>
</section>
<section id="stress-testing">
<h2>Stress Testing<a class="headerlink" href="#stress-testing" title="Permalink to this heading"></a></h2>
<p><a class="reference internal" href="../testing_and_monitoring/validating_models.html"><span class="std std-doc">Stress Testing</span></a> is a
comprehensive set of tests that measure the robustness of your AI
model before deployment. These tests are designed to identify
potential weaknesses and failure modes of your prospective AI
deployment, and each test represents a specific axis of potential
model vulnerability.</p>
<p>The Stress Testing framework comes with a wide range of pre-configured tests, from simple operational risk tests that measure whether model performance is sufficiently high, to complex security tests that identify signatures that are evidence of adversarial attacks. By running hundreds of these tests across both your model and associated datasets, Robust Intelligence can identify potential vulnerabilities in your model, and provide you with insights on how to improve its robustness.</p>
<p>During the development stage of your model’s lifecycle, the Stress Testing framework can help you ensure that your model is performing optimally, across all risk categories. By analyzing individual tests, you can identify areas where your model needs improvement, and refine it accordingly. By identifying these issues early on in the development process, you can address them proactively and ensure that your model is compliant with applicable regulatory or governance standards.</p>
<p>The Stress Testing framework is a powerful tool for measuring the robustness of your AI model before deployment. Its pre-configured tests cover a wide range of potential vulnerabilities, allowing you to identify areas where your model needs improvement, and address them proactively.</p>
</section>
<section id="continuous-testing">
<h2>Continuous Testing<a class="headerlink" href="#continuous-testing" title="Permalink to this heading"></a></h2>
<p><a class="reference internal" href="../testing_and_monitoring/monitoring_models.html"><span class="std std-doc">Continuous Testing</span></a>
is a monitoring tool for AI models during production deployment that
uses the Stress Testing framework applied continually over time. The
framework includes dozens of pre-configured tests that check the
model’s vulnerability to potential failure in production, such as data
drift or detected adversarial attacks.</p>
<p>Continuous Testing can be configured to run on a fixed schedule. On completion we surface vulnerabilities that were discovered in the test run via events and alerts.</p>
<p>To set up Continuous Testing, you can passively log and analyze predictions by uploading prediction logs after model inference. This process can be automated to run at regular intervals.</p>
</section>
<section id="robust-intelligence-inputs">
<h2>Robust Intelligence Inputs<a class="headerlink" href="#robust-intelligence-inputs" title="Permalink to this heading"></a></h2>
<p>To run stress tests (ST) and continuous tests (CT), the platform takes as input:</p>
<ul class="simple">
<li><p><strong>Data</strong>: Robust Intelligence requires
<a class="reference internal" href="../testing_and_monitoring/preparing_your_models_and_datasets/preprocessing_your_datasets.html"><span class="std std-doc">sample data</span></a>
for both ST and CT:</p>
<ul>
<li><p><strong>ST</strong>: A reference dataset and an evaluation dataset are
required. The reference set contains clean training data, and the
evaluation set contains a held-out dataset that the model will
encounter in production. These datasets need to be registered to
the RI Data Registry before usage, and can optionally have
ground truth labels and associated model predictions (which
should be registered to the Prediction Registry). Having this
additional information allows the testing suite to run more
tests than is possible otherwise.</p></li>
<li><p><strong>CT</strong>: The data requirements for CT are an extension of what is
needed for ST. For CT, there is the additional requirement of
passing in production evaluation data periodically (either
manually or via scheduling that you can configure as a part of
the CT instance).</p></li>
</ul>
</li>
<li><p><strong>Model</strong>: Providing access to the
<a class="reference internal" href="../testing_and_monitoring/preparing_your_models_and_datasets/defining_model_interface.html"><span class="std std-doc">model</span></a>
allows for testing the model behavior under different circumstances.
The tests perturb model inputs, provide them to the model, and
examine the model behavior to uncover its vulnerabilities. The model
is treated as a black box, and providing access to the model entails
registering a <code class="docutils literal notranslate"><span class="pre">model.py</span></code> file to the RI Model Registry. The <code class="docutils literal notranslate"><span class="pre">model.py</span></code>
file requires a prediction function that takes in an input from
Robust Intelligence and provides the model prediction given this
input. By treating the model as a black box, Robust Intelligence can
easily integrate with whatever model framework you use.</p></li>
</ul>
</section>
<section id="ai-compliance-management-model-cards">
<h2>AI Compliance Management - Model Cards<a class="headerlink" href="#ai-compliance-management-model-cards" title="Permalink to this heading"></a></h2>
<p>AI Compliance Management allows the user to download auto-generated model cards for internal and external documentation needs. This incorporates results from both Stress Testing and Continuous Testing. These reports help companies comply with AI regulatory standards and maintain a record of testing.</p>
</section>
<section id="workspace-overview">
<h2>Workspace Overview<a class="headerlink" href="#workspace-overview" title="Permalink to this heading"></a></h2>
<p>A Robust Intelligence <a class="reference internal" href="../administration/workspace_configuration/workspaces.html"><span class="std std-doc">workspace</span></a>
is a single pane of glass that provides visibility into all models in
production, providing model health status and the ability to track
models to any custom metric, which is especially useful for AI
leadership in organizations.</p>
</section>
<section id="related-topics">
<h2>Related Topics<a class="headerlink" href="#related-topics" title="Permalink to this heading"></a></h2>
<p><a class="reference internal" href="../testing_and_monitoring/preparing_your_models_and_datasets/defining_model_interface.html"><span class="std std-doc">Defining a Model Interface</span></a><br />
<a class="reference internal" href="../testing_and_monitoring/monitoring_models.html"><span class="std std-doc">Monitor Models with Continuous Tests</span></a><br />
<a class="reference internal" href="../testing_and_monitoring/preparing_your_models_and_datasets/preprocessing_your_datasets.html"><span class="std std-doc">Preprocessing Your Datasets</span></a><br />
<a class="reference internal" href="../testing_and_monitoring/validating_models.html"><span class="std std-doc">Validate Models with Stress Tests</span></a><br />
<a class="reference internal" href="../administration/workspace_configuration/workspaces.html"><span class="std std-doc">Workspaces</span></a></p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="../index.html" class="btn btn-neutral float-left" title="Welcome to Robust Intelligence!" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="get_started.html" class="btn btn-neutral float-right" title="Get Started" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023, Robust Intelligence.</p>
  </div>

   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>
<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Creating a new Continuous Test &mdash; Robust Intelligence  documentation</title>
      <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/copybutton.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/tabs.css" type="text/css" />
      <link rel="stylesheet" href="https://cdn.datatables.net/v/dt/dt-1.13.1/sb-1.4.0/datatables.min.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/custom.css" type="text/css" />
    <link rel="shortcut icon" href="../../_static/favicon.ico"/>
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script src="../../_static/sphinx_highlight.js"></script>
        <script src="../../_static/clipboard.min.js"></script>
        <script src="../../_static/copybutton.js"></script>
        <script src="../../_static/tabs.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script src="../../_static/main.js"></script>
        <script src="https://cdn.datatables.net/v/dt/dt-1.13.1/sb-1.4.0/datatables.min.js"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Creating Projects" href="../creating_projects.html" />
    <link rel="prev" title="Creating a new Stress Test" href="../validating_models/stress_tests_from_sdk.html" />
<link href="../../_static/style.css" rel="stylesheet" type="text/css">

</head>

<body class="wy-body-for-nav">
<div class="ge_header no-print">
    <a id="header-logo" href="../../index.html">
        <img src="../../_static/header-logo.png" alt="logo" />
    </a>
</div>


  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html" class="icon icon-home">
            Robust Intelligence
          </a>
              <div class="version">
                2.0.0-rc.14
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Documentation Home</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../documentation_home/robust_intelligence_intro.html">What is Robust Intelligence?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../documentation_home/get_started.html">Get Started</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Testing and Monitoring</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../creating_projects.html">Creating Projects</a></li>
<li class="toctree-l1"><a class="reference internal" href="../preparing_your_models_and_datasets.html">Preparing your Models and Datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="../validating_models.html">Validate Models with Stress Tests</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../monitoring_models.html">Monitor Models with Continuous Tests</a><ul class="current">
<li class="toctree-l2 current"><a class="current reference internal" href="#">Creating a new Continuous Test</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../notebooks/demo_notebooks/RIME_Firewall_Configuring.html">Updating your Continuous Test</a></li>
<li class="toctree-l2"><a class="reference internal" href="loading_data_for_scheduled_ct.html">Loading Data for Scheduled Continuous Testing</a></li>
<li class="toctree-l2"><a class="reference internal" href="scheduling_ct_runs.html">Scheduling Continuous Testing runs</a></li>
<li class="toctree-l2"><a class="reference internal" href="configuring_scheduled_ct.html">Configuring your Scheduled Continuous Test</a></li>
<li class="toctree-l2"><a class="reference internal" href="ct_feedback_and_observability.html">Continuous Testing Feedback and Observability</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../querying_results.html">Querying Test Run Results</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notifications_and_alerts.html">Notifications and Alerts</a></li>
<li class="toctree-l1"><a class="reference internal" href="../model_governance.html">Managing Model Governance</a></li>
<li class="toctree-l1"><a class="reference internal" href="../configuring_test_runs.html">Configuring your Test Runs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../test_customization.html">Test Customization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../integrating_mlops.html">Integrating with MLOps</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Administration</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../administration/organization_administration.html">Organization Administration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../administration/configuring_workspaces.html">Workspace Configuration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../administration/security_and_compliance.html">Security and Compliance</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Deployment</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../deployment/index.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../deployment/requirements.html">Requirements</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../deployment/installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../deployment/faq.html">FAQ</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../reference/release_notes.html">Release Notes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../reference/python-sdk.html">Python SDK reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../reference/troubleshooting.html">Troubleshooting Home</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../reference/model_tests_reference.html">Model Tests Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../reference/api_changelog.html">API Changelog</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">Robust Intelligence</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../../documentation_home/get_started.html">Get Started</a></li>
          <li class="breadcrumb-item"><a href="../../documentation_home/notebooks.html">Tutorial Notebooks</a></li>
      <li class="breadcrumb-item active">Creating a new Continuous Test</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="creating-a-new-continuous-test">
<span id="continuous-test"></span><h1>Creating a new Continuous Test<a class="headerlink" href="#creating-a-new-continuous-test" title="Permalink to this heading">ÔÉÅ</a></h1>
<p>Robust Intelligence allows you to create a Continuous Test to monitor the performance of a model over time. You can create a Continuous Test in the Web UI or by using the Python SDK.</p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-0-0-0" aria-selected="true" class="sphinx-tabs-tab" id="tab-0-0-0" name="0-0" role="tab" tabindex="0">SDK</button><button aria-controls="panel-0-0-1" aria-selected="false" class="sphinx-tabs-tab" id="tab-0-0-1" name="0-1" role="tab" tabindex="-1">Web UI</button></div><div aria-labelledby="tab-0-0-0" class="sphinx-tabs-panel" id="panel-0-0-0" name="0-0" role="tabpanel" tabindex="0"><p>This procedure presumes a model is already loaded into Robust Intelligence and that all commands are issued in a Python environment.</p>
<ol class="arabic">
<li><p>Create a project using the following <a class="reference internal" href="../../reference/python-sdk.html#rime-sdk"><span class="std std-ref">SDK command</span></a>.</p>
<blockquote>
<div><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">project</span> <span class="o">=</span> <span class="n">rime_client</span><span class="o">.</span><span class="n">create_project</span><span class="p">(</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;foo&quot;</span><span class="p">,</span> <span class="n">description</span><span class="o">=</span><span class="s2">&quot;bar&quot;</span><span class="p">,</span> <span class="n">model_task</span><span class="o">=</span><span class="s2">&quot;MODEL_TASK_BINARY_CLASSIFICATION&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
</div></blockquote>
</li>
<li><p>Register a reference dataset.</p>
<blockquote>
<div><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">reference_id</span> <span class="o">=</span> <span class="n">project</span><span class="o">.</span><span class="n">register_dataset</span><span class="p">(</span>
    <span class="n">name</span><span class="o">=</span><span class="n">DATASET_NAME</span><span class="p">,</span>
    <span class="n">data_params</span><span class="o">=</span><span class="p">{</span>
        <span class="s2">&quot;connection_info&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;data_file&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;path&quot;</span><span class="p">:</span> <span class="n">FILE_PATH</span><span class="p">}},</span>
        <span class="s2">&quot;data_params&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;label_col&quot;</span><span class="p">:</span> <span class="n">LABEL_COL</span><span class="p">},</span>
    <span class="p">},</span>
    <span class="n">integration_id</span><span class="o">=</span><span class="n">INTEGRATION_ID</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div></blockquote>
<p>The SDK returns the ID of the reference dataset.</p>
</li>
<li><p>Register an evaluation dataset.</p>
<blockquote>
<div><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">evaluation_id</span> <span class="o">=</span> <span class="n">project</span><span class="o">.</span><span class="n">register_dataset</span><span class="p">(</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;bar&quot;</span><span class="p">,</span>
    <span class="n">data_config</span><span class="o">=</span><span class="nb">dict</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div></blockquote>
<p>The SDK returns the ID of the evaluation dataset.</p>
</li>
<li><p>Register a model.</p>
<blockquote>
<div><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">project</span><span class="o">.</span><span class="n">register_model</span><span class="p">(</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;baz&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
</div></blockquote>
<p>The SDK returns the model ID.</p>
</li>
<li><p>Register a prediction set.</p>
<blockquote>
<div><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">prediction</span> <span class="o">=</span> <span class="n">project</span><span class="o">.</span><span class="n">register_predictions</span><span class="p">(</span>
    <span class="n">dataset_id</span><span class="o">=</span><span class="n">DATASET_ID</span><span class="p">,</span>
    <span class="n">model_id</span><span class="o">=</span><span class="n">MODEL_ID</span><span class="p">,</span>
    <span class="n">pred_config</span><span class="o">=</span><span class="p">{</span>
        <span class="s2">&quot;connection_info&quot;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s2">&quot;delta_lake&quot;</span><span class="p">:</span> <span class="p">{</span>
                <span class="c1"># Unix timestamp equivalent to 02/08/2023</span>
                <span class="s2">&quot;start_time&quot;</span><span class="p">:</span> <span class="mi">1675922943</span><span class="p">,</span>
                <span class="c1"># Unix timestamp equivalent to 03/08/2023</span>
                <span class="s2">&quot;end_time&quot;</span><span class="p">:</span> <span class="mi">1678342145</span><span class="p">,</span>
                <span class="s2">&quot;table_name&quot;</span><span class="p">:</span> <span class="n">TABLE_NAME</span><span class="p">,</span>
                <span class="s2">&quot;time_col&quot;</span><span class="p">:</span> <span class="n">TIME_COL</span><span class="p">,</span>
            <span class="p">},</span>
        <span class="p">},</span>
        <span class="s2">&quot;pred_params&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;pred_col&quot;</span><span class="p">:</span> <span class="n">PREDS</span><span class="p">},</span>
    <span class="p">},</span>
<span class="p">)</span>
</pre></div>
</div>
</div></blockquote>
<p>The SDK returns the prediction set ID.</p>
</li>
<li><p>Create a new Continuous Test in the project.</p>
<blockquote>
<div><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">project</span><span class="o">.</span><span class="n">create_firewall</span><span class="p">(</span>
    <span class="n">model_id</span><span class="o">=</span><span class="s2">&quot;model&quot;</span><span class="p">,</span> <span class="n">ref_data_id</span><span class="o">=</span><span class="s2">&quot;foo&quot;</span><span class="p">,</span><span class="n">bin_size</span><span class="o">=</span><span class="n">timedelta</span><span class="p">(</span><span class="n">hours</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
</div></blockquote>
</li>
<li><p>Issue the following command to start the Continuous Test, specifying the configuration    created in the previous step and the unique ID of the project that contains the Continuous Test.</p>
<blockquote>
<div><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">continuous_test</span> <span class="o">=</span> <span class="n">firewall</span><span class="o">.</span><span class="n">start_continuous_test</span><span class="p">(</span>
   <span class="n">eval_data_id</span><span class="o">=</span><span class="s2">&quot;bar&quot;</span><span class="p">,</span> <span class="n">override_existing_bins</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div></blockquote>
</li>
</ol>
</div><div aria-labelledby="tab-0-0-1" class="sphinx-tabs-panel" hidden="true" id="panel-0-0-1" name="0-1" role="tabpanel" tabindex="0"><ol class="arabic">
<li><p>Sign in to an RI Platform instance.</p></li>
<li><p>Select a workspace.</p></li>
<li><p>Select a project.</p></li>
<li><p>In the left navigation bar, click <em>Continuous Testing</em>.</p></li>
<li><p>Click <em>Start Continuous Testing</em>.</p></li>
<li><p>Select a set of tests.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Test category</p></th>
<th class="head"><p>Test</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Operational risks</p></td>
<td><p>Overall performance</p></td>
</tr>
<tr class="row-odd"><td><p></p></td>
<td><p>Subset performance</p></td>
</tr>
<tr class="row-even"><td><p></p></td>
<td><p>Drift (continuous testing focus)</p></td>
</tr>
<tr class="row-odd"><td><p></p></td>
<td><p>Transformations (stress testing focus)</p></td>
</tr>
<tr class="row-even"><td><p></p></td>
<td><p>Abnormal inputs (continuous testing focus)</p></td>
</tr>
<tr class="row-odd"><td><p>Security risks</p></td>
<td><p>Adversarial</p></td>
</tr>
<tr class="row-even"><td><p>Fairness risks</p></td>
<td><p>Compliance and fairness</p></td>
</tr>
</tbody>
</table>
</li>
<li><p>Select an overall test sensitivity level.</p></li>
<li><p>Choose a model to test from the list of registered models or register a new model.</p></li>
<li><p>(When using a registered model) Select the model from the <em>Select Model</em> drop-down.</p></li>
<li><p>(When registering a new model) Choose whether to upload a model file or to add a model from an online registry.</p></li>
<li><p>(When uploading a new model) Type a name and tags for the model.</p></li>
<li><p>(When uploading a new model) Drag a <em>pkl</em> or <em>py</em> model file to the wizard or click <em>Select File</em> to browse the file system.</p></li>
<li><p>(When registering a new model from a registry) Type the name of the registry, the URI or file path to the model in the registry, and the registry secret.</p></li>
<li><p>Click <em>Next</em>.</p></li>
<li><p>Choose whether to use a registered reference dataset or a dataset from a connection.</p></li>
<li><p>(Using a registered reference dataset) Type the name of the registered dataset.</p></li>
<li><p>(Using a reference dataset from a connection) Type a connection name, a table name, a timestamp column, and a label column</p></li>
<li><p>(Using a reference dataset from a connection) (Optional) Activate the <em>Predictions (optional)</em> toggle and enter a connection name, table name, optional timestamp column, and prediction column.</p></li>
<li><p>Click <em>Next</em>.</p></li>
<li><p>Select a bin size from the <em>Bin Size</em> drop-down.</p></li>
<li><p>Select a type of reference window from the <em>Reference Window Type</em> drop-down.</p></li>
<li><p>(When the reference window type is Rolling) Select number of bins for the rolling reference window.</p></li>
<li><p>In <em>Data Source</em>, type the name of the evaluation dataset.</p></li>
<li><p>In <em>Table Name</em>, type the name of a table in the evaluation dataset.</p></li>
<li><p>(Optional) Choose a timestamp column in the specified table from the <em>Timestamp Column (optional)</em> drop-down.</p></li>
<li><p>Type a column name in <em>Label Column</em>.</p></li>
<li><p>(Optional) Activate the <em>Predictions (optional)</em> toggle and enter a connection name, table name, optional timestamp column name, and prediction column name.</p></li>
<li><p>Click <em>Next</em>.</p></li>
</ol>
<p>The wizard closes and the new Continuous Test begins initial processing.</p>
</div></div>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="../validating_models/stress_tests_from_sdk.html" class="btn btn-neutral float-left" title="Creating a new Stress Test" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="../creating_projects.html" class="btn btn-neutral float-right" title="Creating Projects" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023, Robust Intelligence.</p>
  </div>

   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>
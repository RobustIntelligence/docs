{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K05kWwxAT9uN"
   },
   "source": [
    "# Robust Intelligence + DataRobot Integration Walkthrough\n",
    "\n",
    "You are a data scientist at a Payment Processing Company. The data science team has been tasked with implementing a Fraud Detection service and monitoring how that model performs over time. The performance of this fraud detection model directly impacts the costs of the company. In order to ensure the data science team develops the best model and the performance of this model doesn't degrade over time, the VP of Data Science purchases the RIME platform.\n",
    "\n",
    "Your team currently does all model development and serving on DataRobot's  intelligent cloud and already uses all of its MLOps tooling.\n",
    "    \n",
    "\n",
    "In this Notebook Walkthrough, we will walkthrough 2 of RIME's core products - **AI Stress Testing** and **AI Firewall** and demonstrate how they integrate with DataRobot's core offerings to help you develop and maintain more robust AI models.\n",
    "\n",
    "1. **AI Stress Testing** is used in the model development stage. Using AI Stress Testing you can test the developed model. RIME goes beyond simply optimizing for basic model performance like accuracy and automatically discovers the model's weaknesses.\n",
    "2. **AI Firewall** is used after the model is deployed in production. Using AI Firewall, you can automate the monitoring, discovery and remediation of issues that occur post-deployment. Additionally it automatically flags, blocks, or imputes erroneous data in real-time.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Latest Colab version of this notebook available [here](https://colab.research.google.com/github/RobustIntelligence/docs/blob/main/notebooks/demo_notebooks/RIME_DataRobot_Integration.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "APMTB6F7byjr"
   },
   "source": [
    "## **Install Dependencies, Import Libraries and Download Data**\n",
    "Run the cell below to install libraries to recieve data, install our SDK, and load analysis libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "k-WEiso6hW8L"
   },
   "outputs": [],
   "source": [
    "%pip install pandas &> /dev/null\n",
    "%pip install datarobot &> /dev/null\n",
    "%pip install rime-sdk &> /dev/null\n",
    "%pip install https://github.com/RobustIntelligence/ri-public-examples/archive/master.zip &> /dev/null\n",
    "\n",
    "from pathlib import Path\n",
    "from tempfile import TemporaryDirectory\n",
    "from typing import Optional\n",
    "\n",
    "import datarobot as dr\n",
    "import pandas as pd\n",
    "from ri_public_examples.download_files import download_files\n",
    "\n",
    "download_files(\"tabular/fraud\", \"fraud_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yv3Y-BBhia1E"
   },
   "source": [
    "## **Connecting to DataRobot**\n",
    "\n",
    "If you do not already have an account with DataRobot, create one now. Once that is done, copy your DataRobot API Key and assign to the variable `DATAROBOT_TOKEN` below.\n",
    "\n",
    "See the [documentation here](https://docs.datarobot.com/en/docs/platform/account-mgmt/acct-settings/api-key-mgmt.html#api-key-management) for more information on DataRobot's API key management console.\n",
    "\n",
    "## **Connecting to RIME**\n",
    "\n",
    "Next, copy your API key for RIME and assign to the variable `RIME_API_TOKEN` below.\n",
    "\n",
    "You can generate a new API key within the 'Workspace settings' page on your RIME cluster's website. \n",
    "\n",
    "Additionally, copy the url of the cluster (e.g., 'rime.\\<cluster-name\\>.rime.dev') to the `RIME_CLUSTER_URL` variable below. (Note: the cluster cannot be `localhost`)\n",
    "\n",
    "Next, we will define some additional constants to help us load the correct datasets for this walkthrough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UkO6_9j5hvLx"
   },
   "outputs": [],
   "source": [
    "# DataRobot User-provided Constants\n",
    "DATAROBOT_TOKEN = \"\"\n",
    "# Endpoint may differ for managed cloud/on-prem/EU/etc.\n",
    "DATAROBOT_ENDPOINT=\"https://app2.datarobot.com/api/v2\"\n",
    "\n",
    "# RIME User-provided Constants\n",
    "RIME_API_TOKEN = \"\"\n",
    "RIME_CLUSTER_URL = \"\" # e.g., \"rime.<cluster>.rime.dev\"\n",
    "\n",
    "# DataRobot project constants\n",
    "dr_project_name = 'Fraud Detection'\n",
    "dr_project_id = None # Set to your DataRobot project ID if you've developed a project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BKkJYmGUh4JU"
   },
   "outputs": [],
   "source": [
    "# Constants for loading the data\n",
    "label_col = \"label\"\n",
    "excluded_cols = ['preds']\n",
    "ref_file = \"fraud_data/data/fraud_ref.csv\"\n",
    "eval_file = \"fraud_data/data/fraud_eval.csv\"\n",
    "incremental_file = \"fraud_data/data/fraud_incremental.csv\"\n",
    "metric = 'LogLoss' # DataRobot recommended metric\n",
    "autopilot_mode = dr.enums.AUTOPILOT_MODE.QUICK\n",
    "\n",
    "# Load the data for training and evaluation\n",
    "train =  pd.read_csv(ref_file).drop(excluded_cols, axis=1)\n",
    "test  =  pd.read_csv(eval_file).drop(excluded_cols, axis=1)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CuXcHBcelroy"
   },
   "source": [
    "## **Develop Models using DataRobot's AutoPilot Service**\n",
    "\n",
    "We have loaded the development datasets above and are ready to train a model. First, we'll define a few helper functions (not RIME-specific)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "TKwGgzomh4nz"
   },
   "outputs": [],
   "source": [
    "#@title Helper Functions (Hidden)\n",
    "def get_model_score(model: dr.Model, metric: str):\n",
    "    res = {}\n",
    "    res['model_number'] = model.model_number\n",
    "    res['model_type'] = model.model_type\n",
    "    res['model'] = model\n",
    "    res['sample_pct'] = model.sample_pct\n",
    "\n",
    "    res['metric_v'] = model.metrics.get(metric, {}).get('validation')\n",
    "    res['metric_cv'] = model.metrics.get(metric, {}).get('crossValidation')\n",
    "\n",
    "    return res\n",
    "\n",
    "def get_train_preds(model: dr.Model) -> pd.DataFrame:\n",
    "    \"\"\"Request and/or retrieve training predictions for a given model.\"\"\"\n",
    "    try:\n",
    "        # Request training predictions and get job IDs\n",
    "        pred_job = model.request_training_predictions(dr.enums.DATA_SUBSET.ALL)\n",
    "        preds = pred_job.get_result_when_complete().get_all_as_dataframe()\n",
    "        return preds\n",
    "    except:\n",
    "        # Retrieve training predictions if they were already requested\n",
    "        train_preds = dr.TrainingPredictions.list(model.project_id)\n",
    "        for train_pred in train_preds:\n",
    "            if train_pred.model_id == model.id and train_pred.data_subset == 'all':\n",
    "                preds = dr.TrainingPredictions.get(model.project_id, train_pred.prediction_id).get_all_as_dataframe()\n",
    "                return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cTGvUDvLYx3z"
   },
   "source": [
    "### **Create DataRobot Client and Project**\n",
    "\n",
    "Before we train a model, we need to connect to our DataRobot account and create a new project (or connect to an existing one). Once the project is made, we can begin Autopilot to develop and select a model that performs well on the training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bf9NO15r35q4"
   },
   "outputs": [],
   "source": [
    "# To connect from a Zepl notebook:\n",
    "# dr_client = dr.Client(token=z.getDatasource(\"datarobot_api\")['token'] , endpoint=DATAROBOT_ENDPOINT)\n",
    "\n",
    "# To connect from a Jupyter notebook:\n",
    "dr_client = dr.Client(endpoint=DATAROBOT_ENDPOINT, token=DATAROBOT_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZuVbXNi84A2N"
   },
   "outputs": [],
   "source": [
    "if dr_project_id is None:\n",
    "    dr_project = dr.Project.create(project_name=dr_project_name, sourcedata=train)\n",
    "    dr_project.set_target(\n",
    "        target=label_col,\n",
    "        worker_count = '-1',\n",
    "        mode=autopilot_mode\n",
    "    )\n",
    "\n",
    "    dr_project.wait_for_autopilot(verbosity=1)  # Wait for autopilot to complete\n",
    "    dr_project_id = dr_project.id\n",
    "else:\n",
    "    dr_project = dr.Project.get(project_id=dr_project_id)\n",
    "test_dr_dataset = dr_project.upload_dataset(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JWLphBNG4HtX"
   },
   "outputs": [],
   "source": [
    "# Fetch models trained on at least 60% of the uploaded dataset\n",
    "models = dr_project.get_models(\n",
    "    search_params={\n",
    "        'sample_pct__gt': 60,\n",
    "    }\n",
    ")\n",
    "# Order by AUC computed during cross-validation\n",
    "models = sorted(models, key=lambda model: get_model_score(model, 'AUC')['metric_cv'] or -1, reverse=True)\n",
    "# Choose model with highest training AUC to evaluate on RIME\n",
    "model = models[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aP8np_fK6VcA"
   },
   "source": [
    "### **Compute Model Predictions**\n",
    "\n",
    "Now that we've trained the model with Autopilot, let's prepare the data and model for RIME to see how it can provide us with more in-depth information and recommendations for making our model as robust as possible. \n",
    "\n",
    "First, we'll compute the model predictions for the evaluation dataset to speed up our RIME run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IwRPnX5Q6UNP"
   },
   "outputs": [],
   "source": [
    "pred_col_name = \"pred\"\n",
    "predict_job = model.request_predictions(test_dr_dataset.id)\n",
    "predictions = predict_job.get_result_when_complete()\n",
    "test_with_preds = test.copy()\n",
    "test_with_preds[pred_col_name] = predictions['positive_probability']\n",
    "train_with_preds = train.copy()\n",
    "train_with_preds[pred_col_name] = get_train_preds(model)['class_1.0']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bOtRe8eha_Qn"
   },
   "source": [
    "Next, we'll deploy the model to facilitate a loose integration with RIME."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dlsxXKhh6nK3"
   },
   "outputs": [],
   "source": [
    "# Deploy model\n",
    "def deploy_model(model: dr.Model) -> dr.Deployment:\n",
    "    \"\"\"Create a deployed model endpoint.\"\"\"\n",
    "    deployment = dr.Deployment.create_from_learning_model(\n",
    "      model_id=model.id, label=\"Fraud Detection Deployment\",\n",
    "      description=\"Deployed with DataRobot client\")\n",
    "\n",
    "    # View deployment stats\n",
    "    service_stats = deployment.get_service_stats()\n",
    "    print(service_stats.metrics)\n",
    "    return deployment\n",
    "\n",
    "deployment = deploy_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OfNVVGgEGJkC"
   },
   "source": [
    "### **Connecting to RIME**\n",
    "Now for the fun. To connect to RIME, we use the API key and cluster URL specified above. \n",
    "You can generate a new API key within the 'Workspace settings' page on your RIME cluster's website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "59I5b5_GlaWZ"
   },
   "outputs": [],
   "source": [
    "from rime_sdk import Client, Project, Job\n",
    "\n",
    "rime_client = Client(RIME_CLUSTER_URL, api_key=RIME_API_TOKEN)\n",
    "rime_project = rime_client.create_project(name='DataRobot Demo', \n",
    "                                          description='Create an e2e RIME Demo using DataRobot.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GPFBP2gu7ah6"
   },
   "source": [
    "### **Define Helper Functions**\n",
    "\n",
    "Below, define functions to assist us in:\n",
    "-  creating a `model.py` file that connects with the model endpoint deployed above.\n",
    "- uploading the model and data to the RIME cluster.\n",
    "- configuring the RIME run and initializing stress testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "eFTucMtT7a8i"
   },
   "outputs": [],
   "source": [
    "#@title Helper Functions\n",
    "def get_model_file_contents(deployment: dr.Deployment, api_token: str) -> str:\n",
    "    \"\"\"Return the stringified model.py file.\"\"\"\n",
    "    api_url = deployment.default_prediction_server[\"url\"]\n",
    "    deployment_id = deployment.id\n",
    "    file_str = \"\"\"\\\"\\\"\\\"Template for how you can use RIME for a model hosted on DataRobot.\n",
    "\n",
    "We expect this file to contain a `predict_dict` function that takes in a mapping from\n",
    "feature name to feature value. This corresponds to one row in the dataset. This\n",
    "method should return a score between 0 and 1.\n",
    "\n",
    "\n",
    "This specific file implements this assuming that 1) your model is hosted\n",
    "on DataRobot, and 2), that your machine is authenticated with Google Cloud,\n",
    "and 3) that you have the requests library installed.\n",
    "\n",
    "\\\"\\\"\\\"\n",
    "\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "\n",
    "# Step 1: Define endpoint variables.\n",
    "\"\"\"\n",
    "    file_str += f'API_URL = \"{api_url}/predApi/v1.0/deployments\"\\n'\n",
    "    file_str += f\"API_KEY = '{api_token}'\\n\"\n",
    "    file_str += f\"DEPLOYMENT_ID = '{deployment_id}'\\n\"\n",
    "    file_str += \"\"\"\n",
    "URL = API_URL + f\"/{DEPLOYMENT_ID}/predictions\"\n",
    "HEADERS = {\n",
    "        'Content-Type': 'application/json; charset=UTF-8',\n",
    "        'Authorization': 'Bearer {}'.format(API_KEY),\n",
    "    }\n",
    "\n",
    "MAX_PREDICTION_FILE_SIZE_BYTES = 52428800  # 50 MB\n",
    "\n",
    "\n",
    "def predict_df(df: pd.DataFrame) -> np.ndarray:\n",
    "    \\\"\\\"\\\"Return array of probabilities assigned to the positive class.\\\"\\\"\\\"\n",
    "    data = pd.DataFrame.to_json(df, orient=\"records\")\n",
    "    # breakpoint()\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json; charset=UTF-8\",\n",
    "        \"Authorization\": \"Bearer {}\".format(API_KEY),\n",
    "    }\n",
    "\n",
    "    # Make API request for predictions\n",
    "    success = False\n",
    "    while not success:\n",
    "        predictions_response = requests.post(URL, data=data, headers=headers,)\n",
    "        # Make sure we are not running into a 429 (too many requests) error\n",
    "        if predictions_response.status_code == 429:\n",
    "            time.sleep(int(predictions_response.headers[\"Retry-After\"]))\n",
    "        else:\n",
    "            success = True\n",
    "    # Get response data\n",
    "    res = predictions_response.json()[\"data\"]\n",
    "    # Get the prediction for the case where label == 1\n",
    "    # NOTE: this is only for binary classification\n",
    "    preds = []\n",
    "    for pred in res:\n",
    "        for val in pred[\"predictionValues\"]:\n",
    "            if val[\"label\"] == 1:\n",
    "                preds.append(val[\"value\"])\n",
    "                break\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                f\"No prediction for input row {pred['rowId']} and label == 1\"\n",
    "            )\n",
    "    return np.array(preds)\n",
    "    \"\"\"\n",
    "    return file_str\n",
    "\n",
    "\n",
    "def upload_model(\n",
    "    deployment: dr.Deployment, api_token: str, client: Client\n",
    ") -> str:\n",
    "    \"\"\"Upload trained model to RIME cluster and return the resultant model directory path.\"\"\"\n",
    "    upload_path = \"datarobot_demo\"\n",
    "    with TemporaryDirectory() as d:\n",
    "        _dir = Path(d)\n",
    "        extras_dir = _dir / \"model_extras\"\n",
    "        extras_dir.mkdir()\n",
    "        with open(_dir / \"model.py\", \"w\") as f:\n",
    "            f.write(get_model_file_contents(deployment, api_token))\n",
    "        uploaded_path = client.upload_directory(d, upload_path=upload_path)\n",
    "    return uploaded_path + \"/model.py\"\n",
    "\n",
    "\n",
    "def upload_dataset_file(client: Client, df: pd.DataFrame, split: str) -> str:\n",
    "    \"\"\"Upload dataframe to RIME cluster.\"\"\"\n",
    "    upload_path = \"datarobot_demo\"\n",
    "    with TemporaryDirectory() as d:\n",
    "        f = Path(d) / f\"{split}_data.csv\"\n",
    "        df.to_csv(f, index=False)\n",
    "        uploaded_name = client.upload_file(f.resolve(), upload_path=upload_path)\n",
    "    return uploaded_name\n",
    "\n",
    "\n",
    "def prepare_test_config(\n",
    "    rime_ref_path: str,\n",
    "    rime_eval_path: str,\n",
    "    rime_model_path: str,\n",
    "    net_name: str,\n",
    "    label_col: str,\n",
    "    pred_col: Optional[str] = None,\n",
    ") -> dict:\n",
    "    \"\"\"Prepare a test config from the given paths.\"\"\"\n",
    "    test_config = {\n",
    "        \"run_name\": f\"{net_name} DataRobot Experiment\",\n",
    "        \"data_info\": {\"label_col\": label_col},\n",
    "        \"model_info\": {},\n",
    "        \"model_task\": \"Binary Classification\",\n",
    "    }\n",
    "    if pred_col is not None:\n",
    "        test_config[\"data_info\"][\"pred_col\"] = pred_col\n",
    "    test_config[\"data_info\"][\"ref_path\"] = rime_ref_path\n",
    "    test_config[\"data_info\"][\"eval_path\"] = rime_eval_path\n",
    "    test_config[\"model_info\"][\"path\"] = rime_model_path\n",
    "    return test_config\n",
    "\n",
    "\n",
    "def run_rime_stress_tests(\n",
    "    test_config: dict, client: Client, project: Project\n",
    ") -> Job:\n",
    "    \"\"\"Run the stress tests for RIME.\"\"\"\n",
    "    stress_test_job = client.start_stress_test(\n",
    "        test_config, project_id=project.project_id\n",
    "    )\n",
    "    stress_test_job_status = stress_test_job.get_status(\n",
    "        verbose=True, wait_until_finish=True\n",
    "    )\n",
    "    if stress_test_job_status[\"status\"] == \"JOB_STATUS_SUCCEEDED\":\n",
    "        return stress_test_job\n",
    "    raise Exception(f\"Stress test job run failing. {stress_test_job_status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CdKhO9NkbtD7"
   },
   "source": [
    "### **Upload Data + Model**\n",
    "\n",
    "Below, upload data and the model file, then kick off a stress testing run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LKGYMELX7-5I"
   },
   "outputs": [],
   "source": [
    "net_name = \"Fraud Detection Model\"\n",
    "rime_ref_path = upload_dataset_file(rime_client, train_with_preds, \"ref\")\n",
    "rime_eval_path = upload_dataset_file(rime_client, test_with_preds, \"eval\")\n",
    "rime_model_path = upload_model(deployment, DATAROBOT_TOKEN, rime_client)\n",
    "test_config = prepare_test_config(rime_ref_path, rime_eval_path, rime_model_path, net_name, label_col, pred_col=pred_col_name)\n",
    "stress_job = run_rime_stress_tests(test_config, rime_client, rime_project)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ovrKDoifIxIm"
   },
   "source": [
    "## **Stress Test Results**\n",
    "\n",
    "Stress stest are grouped into categories that measure various aspects of model robustness (model behavior, distribution drift, abnormal input, transformations, adversarial attacks, data cleanliness). Suggestions to improve your model are aggregated on the category level as well. Tests are ranked by default by a shared severity metric. Clicking on an individual test surfaces more detailed information. \n",
    "\n",
    "\n",
    "You can view the detailed results in the UI by running the below cell and redirecting to the generated link. This page shows granular results for a given AI Stress Test run. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h2iYOcGiI16-"
   },
   "outputs": [],
   "source": [
    "test_run = stress_job.get_test_run()\n",
    "test_run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1zKDo7TOYYds"
   },
   "source": [
    "### **Analyzing the Results**\n",
    "\n",
    "Navigate the link printed in the above code block to identify issues with the current model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XGivw_Weookf"
   },
   "source": [
    "### **Programmatically Querying the Results**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HB4A2GouWysL"
   },
   "source": [
    "RIME not only provides you with an intuitive UI to visualize and explore these results, but also allows you to programmatically query these results. This allows you to integrate with any MLOps pipeline, log results to experiment management tools like MLFlow, bring automated decision making to your ML practices, or store these results for future references. \n",
    "\n",
    "Run the below cell to programmatically query the results. The results are outputed as a pandas dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fTWLakM8VQj6"
   },
   "source": [
    "**Access results at the a test run overview level**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dgawCIZWLFST"
   },
   "outputs": [],
   "source": [
    "test_run_result = test_run.get_result_df()\n",
    "test_run_result.to_csv(\"Fraud_Test_Run_Results.csv\")\n",
    "test_run_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tUUcNh7XVUPl"
   },
   "source": [
    "**Access detailed test results at each individual test cases level.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u2qh2linVIt9"
   },
   "outputs": [],
   "source": [
    "test_case_result = test_run.get_test_cases_df(show_test_case_metrics=True)\n",
    "test_case_result.to_csv(\"Fraud_Test_Case_Results.csv\")\n",
    "test_case_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5f7LPX1pqOhP"
   },
   "source": [
    "## **Deploy to Production and Create the AI Firewall**\n",
    "\n",
    "Once you have identified the best stress test run, you can deploy the associated model wrapped with the AI Firewall. The AI Firewall operates on both a datapoint and batch level. It automatically protects your model in real-time from “bad” incoming data and also alerts on statistically significant distributional drift. \n",
    "\n",
    "In this scenario, the data scientist is short on time and decided to deploy the existing model to production. The data scientist also creates and wraps a firewall around the model. The AI Firewall is automatically configured based on the failures identified by AI Stress testing to protect the tested model in Production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9ZkM8lX4qUMh"
   },
   "outputs": [],
   "source": [
    "firewall = rime_project.create_firewall(name=\"DataRobot Firewall\", bin_size='day', test_run_id=test_run.test_run_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a0Lw2YBXBkb4"
   },
   "source": [
    "## **Uploading a Batch of Production Data & Model Predictions to Firewall**\n",
    "\n",
    "The fraud detection model has been in production for 30 days. Production data and model predictions have been collected and stored for the past 30 days. Now, we will use Firewall to track how the model performed across the last 30 days. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g7McYwfDUztC"
   },
   "source": [
    "**Upload an Incremental Batch of Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zsmlbMIFUzAy"
   },
   "outputs": [],
   "source": [
    "# Fetch the production data\n",
    "TIMESTAMP_COL = \"timestamp\"\n",
    "incremental_df = pd.read_csv(incremental_file).drop(excluded_cols, axis=1)\n",
    "\n",
    "# Group by week to simulate running weekly batches\n",
    "# This isn't a requirement, as RIME can perform the grouping itself\n",
    "timestamps_dt = pd.DatetimeIndex(incremental_df[TIMESTAMP_COL])\n",
    "for name, group in incremental_df[TIMESTAMP_COL].groupby(timestamps_dt.to_period(\"W-SUN\").to_timestamp()):\n",
    "    split_name = name.split(' ')[0]\n",
    "    print(f\"Running batch for week {split_name}\")\n",
    "    batch_df = incremental_df.loc[group.index]\n",
    "    # Upload to datarobot to make predictions. In a real deployment, \n",
    "    # this step would have been done already\n",
    "    prod_dr_dataset = dr_project.upload_dataset(batch_df)\n",
    "    predict_job = model.request_predictions(prod_dr_dataset.id)\n",
    "    predictions = predict_job.get_result_when_complete()\n",
    "    batch_df[pred_col_name] = predictions['positive_probability']\n",
    "    # Upload production data with preds to the RIME cluster\n",
    "    rime_incremental_path = upload_dataset_file(rime_client, batch_df, split_name)\n",
    "    incremental_config = {\n",
    "        \"eval_path\": rime_incremental_path,\n",
    "        \"timestamp_col\": TIMESTAMP_COL\n",
    "    }\n",
    "    ct_job = firewall.start_continuous_test(test_run_config=incremental_config, disable_firewall_events=False)\n",
    "    ct_job.get_status(verbose=True, wait_until_finish=True)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ifxKz_p6Uc63"
   },
   "source": [
    "**Wait for a couple minutes and your results will appear in the UI.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TxvbFoou3LUG"
   },
   "source": [
    "\n",
    "## **Firewall Overview**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pfMzlUjl3W7M"
   },
   "outputs": [],
   "source": [
    "firewall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jUyMwqUx3XTW"
   },
   "source": [
    "The Overview page is the mission control for your model’s production deployment health. In it, you can see the status of firewall events, get notified when model performance degrades, and see the underlying causes of failure.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MzMea8BUFOT1"
   },
   "source": [
    "## **Firewall CT Results**\n",
    "\n",
    "The AI Firewall’s Continuous Tests operate at the batch level and provide a mechanism to monitor the health of ML deployments in production. They allow the user to understand when errors begin to occur and surface the underlying drivers of such errors. \n",
    "\n",
    "You can explore the results in the UI by running the below cell and redirecting to the generated link.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ycu422woQkoA"
   },
   "source": [
    "### **Analyzing CT Results**\n",
    "\n",
    "Navigate to the \"Continuous Tests\" tab to explore various test metrics over the past month. This view captures some important insights, such as:\n",
    "\n",
    "- **Abnormality rate increases** - By changing the \"Metric\" to \"Abnormality Rate\", we can see that very few abnormal inputs are seen at the outset of the month. By month's end, the abnormality rate has shot up to 28.6% \n",
    "\n",
    "- **Prediction Percentiles dropped over time** - By changing the metric to \"Prediciton Percentiels\", we can see that the 50% at the beginning of the month was 0.7, but it dropped to 0.538 by month's end.\n",
    "\n",
    "- **Prediction drift increases over time** When evaluating the Prediction Drift, we can see it has increased over time. On 08/01, when the model was deployed, PSI was 0.54. By 08/29, PSI had increased to 2.17. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7pbPUQ2CFTZg"
   },
   "source": [
    "## **Firewall Realtime Events Results**\n",
    "\n",
    "The AI Firewall’s Realtime Events tab operates at the datapoint-level to simultaneously alert and protect your model against issues in real-time. It tracks and surfaces the datapoints that were flagged when entering the AI system.\n",
    "\n",
    "We can see that for the flagged datapoints in the latest time bucket, the \"browser_version\" feature is failing. We may dig in further by clicking on a flagged row to see the reason it was flagged. In this case, there was a new feature value for \"browser_version\" that the model had not encountered during the model development phase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SIElfbMLGUeD"
   },
   "source": [
    "##  **What's Next?**\n",
    "\n",
    "Try RIME on your own data and models. You can use [this tutorial](https://colab.research.google.com/drive/1kiFMTcNpmWkr00PhhS0E1bbOBwTlCWXr?usp=sharing#scrollTo=Zm8wT42kwhT0) to help you started!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "RIME_DataRobot_Integration.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "ca72df3b9ba417119a386bc7f6836e81c78349bc450cdbaf3afafb90bdf8ed1f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K05kWwxAT9uN"
   },
   "source": [
    "# Using a Data Collector for Scheduled Continuous Testing\n",
    "   \n",
    "\n",
    "In this Notebook walkthrough, we will show how to create an **AI Firewall**, log points to a **data collector**, and **schedule automatic tests** with it. The Data Collector can be used to log datapoints in a production setting and batch setting, which can be coupled with a a scheduler to automatically run continuous tests on data, with no extra configuration. We will also show you how to kick off manual testing runs with the collector.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Latest Colab version of this notebook available [here](https://colab.research.google.com/github/RobustIntelligence/docs/blob/main/notebooks/demo_notebooks/RIME_DataCollector_Configuring.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "APMTB6F7byjr"
   },
   "source": [
    "**Create a Firewall and Schedule Tests**\n",
    "After specifying the required credentials, run the cells below to install libraries, run stress testing, and deploy an AI Firewall with Data Collector. For a more fine-grained walkthrough of this code, please reference our Fraud Onboarding Walkthrough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_TOKEN = '' # PASTE API_KEY \n",
    "CLUSTER_URL = '' # PASTE DEDICATED DOMAIN OF RIME SERVICE (eg: rime.stable.rbst.io)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See the Fraud Onboarding Walkthrough for more information on the following code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install rime-sdk &> /dev/null\n",
    "!pip install https://github.com/RobustIntelligence/ri-public-examples/archive/master.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-Qr8pHVOcNz7",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from tempfile import TemporaryDirectory\n",
    "from typing import List\n",
    "\n",
    "import pandas as pd\n",
    "from ri_public_examples.download_files import download_files\n",
    "from rime_sdk import Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rime_client = Client(CLUSTER_URL, API_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "description = (\n",
    "    \"Create an AI Firewall, log data directly to the Robust Intelligence platform,\"\n",
    "    \" and schedule automated Continuous Testing of your deployed model. All using\"\n",
    "    \" the RIME SDK. Demonstration uses a tabular binary classification dataset\"\n",
    "    \" and model that simulates credit card fraud detection.\"\n",
    ")\n",
    "project = rime_client.create_project(\n",
    "    name='AI Firewall Data Collector Demo', \n",
    "    description=description,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch example data\n",
    "download_files('tabular/fraud', 'fraud')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload data to cluster storage\n",
    "upload_path = \"ri_public_examples_fraud\"\n",
    "rime_training_path = rime_client.upload_file(Path('fraud/data/fraud_ref.csv'), upload_path=upload_path)\n",
    "rime_testing_path = rime_client.upload_file(Path('fraud/data/fraud_eval.csv'), upload_path=upload_path)\n",
    "fraud_model_path = rime_client.upload_directory(Path('fraud/models'), upload_path=upload_path)\n",
    "fraud_model_path = fraud_model_path + \"/fraud_model.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Stress Tests\n",
    "stress_test_config = {\n",
    "    \"run_name\": \"Fraud Model\", \n",
    "    \"data_info\": {\n",
    "        \"pred_col\": \"preds\",\n",
    "        \"label_col\": \"label\", \n",
    "        \"ref_path\": rime_training_path, \n",
    "        \"eval_path\": rime_testing_path\n",
    "    }, \n",
    "    \"model_info\": {\n",
    "        \"path\": fraud_model_path\n",
    "    }, \n",
    "    \"model_task\":\"Binary Classification\"\n",
    "}\n",
    "stress_job = rime_client.start_stress_test(test_run_config=stress_test_config, project_id=project.project_id)\n",
    "stress_job.get_status(verbose=True, wait_until_finish=True)\n",
    "stress_test_run = stress_job.get_test_run()\n",
    "\n",
    "# You can view the test run results in the provided link\n",
    "stress_test_run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g7McYwfDUztC"
   },
   "source": [
    "## **Upload Continuous Testing Data to the Data Collector**\n",
    "\n",
    "The following function simulates a batch upload of production data to the data collector in a real time setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rime_sdk.data_collector import DataCollector\n",
    "# Load the data to be used to simulate multiple days of production\n",
    "continuous_testing_data = pd.read_csv(\"fraud/data/fraud_incremental.csv\")\n",
    "\n",
    "def log_datapoints(\n",
    "    data_collector: DataCollector, df: pd.DataFrame, pred_col: str, label_col: str, timestamp_col: str, keep_timestamps: bool = False\n",
    ") -> None:\n",
    "    \"\"\"Log Dataframe to Data Collector\"\"\"\n",
    "    preds = list(df[pred_col])\n",
    "    labels = list(df[label_col])\n",
    "    timestamps = None\n",
    "    if keep_timestamps:\n",
    "        timestamps = list(df[timestamp_col])\n",
    "    df_dict = df.drop(columns=[pred_col, label_col, timestamp_col]).to_dict(\"records\")\n",
    "    data_collector.log_datapoints(\n",
    "        df_dict, preds=preds, labels=labels, timestamps=timestamps\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**You can see the current Firewall status in the UI by clicking the link below. Events will populate once you run the subsequent cell.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an AI Firewall\n",
    "firewall = project.create_firewall(name=\"Data Collector Scheduled CT Firewall\", bin_size=\"hour\", test_run_id=stress_test_run.test_run_id)\n",
    "firewall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Activate the Schedule and Use the Data Collector**\n",
    "\n",
    "The scheduler can be configured to run according to the bin size of the data - every hour, every day, etc. Configure a schedule associated with the firewall, to run with data from the data collector. Then get the data collector and start logging points. We will be attaching real-time timestamps to these datapoints to simulate a production setting. This is done by default in the data collector if no timestamps are attached."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activate a Schedule for the Data Collector\n",
    "firewall.activate_ct_schedule(location_type=\"data_collector\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the Data Collector\n",
    "collector = firewall.get_data_collector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRED_COL = \"preds\"\n",
    "LABEL_COL = \"label\"\n",
    "TIMESTAMP_COL = \"timestamp\"\n",
    "\n",
    "# Log datapoints to the collector\n",
    "log_datapoints(collector, continuous_testing_data, pred_col=PRED_COL, label_col=LABEL_COL, timestamp_col=TIMESTAMP_COL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you've logged datapoints to the data collector, the scheduler should display results within an hour."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Create a Firewall and Test Data Manually**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use the data collector in manual Continuous Testing runs without depending on the scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = rime_client.create_project(name='Firewall Data Collector Manual Configuration Demo', description='This is an Onboarding Demo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stress_job = rime_client.start_stress_test(test_run_config=stress_test_config, project_id=project.project_id)\n",
    "stress_job.get_status(verbose=True, wait_until_finish=True)\n",
    "stress_test_run = stress_job.get_test_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an AI Firewall\n",
    "firewall = project.create_firewall(name=\"Data Collector Manual Firewall\", bin_size=\"day\", test_run_id=stress_test_run.test_run_id)\n",
    "firewall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this example, we will keep the original timestamps associated with the data. The Data Collector has a TTL of 1 year, so we will need to adjust the timestamps first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "continuous_testing_data = pd.read_csv(\"fraud/data/fraud_incremental.csv\")\n",
    "\n",
    "curr_year = datetime.datetime.now().year\n",
    "continuous_testing_data[\"timestamp\"] = continuous_testing_data[\"timestamp\"].str.replace('2018',f\"{curr_year}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_format = \"%Y-%m-%d\"\n",
    "earliest_timestamp = datetime.datetime.strptime(continuous_testing_data[\"timestamp\"].min(), time_format)\n",
    "latest_timestamp = datetime.datetime.strptime(continuous_testing_data[\"timestamp\"].max(), time_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the Data Collector\n",
    "collector = firewall.get_data_collector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRED_COL = \"preds\"\n",
    "LABEL_COL = \"label\"\n",
    "TIMESTAMP_COL = \"timestamp\"\n",
    "\n",
    "# Log datapoints to the collector\n",
    "log_datapoints(collector, continuous_testing_data, pred_col=PRED_COL, label_col=LABEL_COL, timestamp_col=TIMESTAMP_COL, keep_timestamps=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run a continuous test from 08/01 to 08/15. The continuous testing config expects start time and end time to be in unix seconds, so we need to do a quick conversion below and start the test. You can review the results in the UI below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "request_end_date = datetime.datetime(curr_year, 8, 15)\n",
    "incremental_config = {\n",
    "    \"eval_data_info\": {\n",
    "        \"type\": \"data_collector\",\n",
    "        \"start_time\": int(earliest_timestamp.timestamp()),\n",
    "        \"end_time\": int(request_end_date.timestamp())\n",
    "    }\n",
    "}\n",
    "\n",
    "ct_job = firewall.start_continuous_test(incremental_config)\n",
    "ct_job.get_status(verbose=True, wait_until_finish=True)\n",
    "firewall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update Reference Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now suppose that we have updated your model by retraining on new data from the first half of August. We want to update our deployed Firewall to reflect the new reference dataset.\n",
    "\n",
    "However, it's even easier to adapt all of the tests and configuration parameters by updating  the firewall based on the data stored on the collector during that time period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the reference set by setting the reference time period to the first have of august\n",
    "firewall.update_scheduled_ct_info(location_type=\"data_collector\", reference_set_time_bin=(earliest_timestamp, request_end_date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can see that the 'refDataInfo', which is the reference set now contains the reference period we set it to\n",
    "# in unix seconds\n",
    "firewall.get_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's kick off another continuous test run for the second half of August, now that we've changed our baseline data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the new request start date to 08/16\n",
    "new_start_date = request_end_date + datetime.timedelta(days=1)\n",
    "\n",
    "new_incremental_config = {\n",
    "    \"eval_data_info\": {\n",
    "        \"type\": \"data_collector\",\n",
    "        \"start_time\": int(new_start_date.timestamp()),\n",
    "        \"end_time\": int(latest_timestamp.timestamp())\n",
    "    }\n",
    "}\n",
    "ct_job = firewall.start_continuous_test(new_incremental_config)\n",
    "ct_job.get_status(verbose=True, wait_until_finish=True)\n",
    "firewall"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "RIME_Fraud_OnboardingWalkthrough.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd9c562c",
   "metadata": {},
   "source": [
    "# **RI Adversarial File Scanning Walkthrough**\n",
    "\n",
    "> ▶️ **Try this in Colab!** Run the [RI Adversarial File Scanning Walkthrough in Google Colab](https://colab.research.google.com/github/RobustIntelligence/docs/blob/main/notebooks/demo_notebooks/RIME_Adversarial_NLP_Walkthrough.ipynb). \n",
    "\n",
    "You are the AI Risk Officer at a Consumer Social Company. The NLP team has been tasked with implementing a text classification model to predict the top-level \"sentiment\" of posts on the app. These predictions will later be consumed by multiple models throughout the company, such as recommendation, lead prediction, and the core advertisement models. You want to verify your models are sufficiently robust to adversaries seeking to exploit model vulnerabilities and boost content that your user base does not actually like.\n",
    "\n",
    "In this Notebook Walkthrough, we will review our core product of **AI Stress Testing** of NLP models in an *adversarial setting*. RIME AI Stress Testing allows you to test any text classification model on any dataset. In this way, you will be able to quantify your model's vulnerability to attacks and noisy data.\n",
    "\n",
    "Your team's NLP models are fine-tuned from state-of-the-art transformer models found on [Hugging Face's Model Hub 🤗](https://huggingface.co/models). In particular, you have chosen to fine-tune a [DistilBERT](https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english) on data similar to the [Stanford Sentiment Treebank](https://huggingface.co/datasets/sst2) dataset for a lightweight yet performant model. \n",
    "\n",
    "For more information on how to connect with a [Hugging Face Model](https://readthedocs.com/cas/login?service=https%3A%2F%2Frobust-intelligence-inc-rime.readthedocs-hosted.com%2Fen%2Flatest%2Ffor_data_scientists%2Fhow_to_guides%2Fintegrations%2Fhuggingface.html%3Fnext%3Dhttps%253A%252F%252Frobust-intelligence-inc-rime.readthedocs-hosted.com%252Fen%252Flatest%252Ffor_data_scientists%252Fhow_to_guides%252Fintegrations%252Fhuggingface.html%253Fhighlight%253Dhuggingface#huggingface-classification-model) or \n",
    "[Hugging Face Dataset](https://readthedocs.com/cas/login?service=https%3A%2F%2Frobust-intelligence-inc-rime.readthedocs-hosted.com%2Fen%2Flatest%2Ffor_data_scientists%2Freference%2Fconfiguration%2Fnlp%2Fdata_source.html%3Fnext%3Dhttps%253A%252F%252Frobust-intelligence-inc-rime.readthedocs-hosted.com%252Fen%252Flatest%252Ffor_data_scientists%252Freference%252Fconfiguration%252Fnlp%252Fdata_source.html%253Fhighlight%253Dhuggingface#huggingface-dataset), check out the linked documentation.\n",
    "\n",
    "To begin, please specify your RIME cluster's URL and personal access token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28e7fdf-4155-4130-95e0-07825beb28c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install rime-sdk &> /dev/null\n",
    "!pip install seaborn\n",
    "\n",
    "from rime_sdk import Client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955fb070-7b37-4288-99a5-ea5967b6028b",
   "metadata": {
    "id": "90zo7hdkmKyW",
    "tags": []
   },
   "source": [
    "## **Establish the RIME Client**\n",
    "\n",
    "To get started, provide the API credentials and the base domain/address of the RIME service. You can generate and copy an API token from the API Access Tokens Page under Workspace settings. For the domian/address of the RIME service, contact your admin. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a0e5b1-2f69-4819-a9c8-5455c3848e7f",
   "metadata": {
    "id": "90zo7hdkmKyW"
   },
   "source": [
    "![img_1](https://drive.google.com/uc?id=1vMDhZii8yq22iuqSM8-Vqt3sZ2F3tPyz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6b3853-b365-4444-b629-3bc8b36f4cf8",
   "metadata": {
    "id": "Ns6m8I-qsCzF"
   },
   "outputs": [],
   "source": [
    "API_TOKEN = '' # PASTE API_KEY \n",
    "CLUSTER_URL = '' # PASTE DEDICATED DOMAIN OF RIME SERVICE (eg: rime.stable.rbst.io)\n",
    "AGENT_ID = '' # PASTE AGENT_ID IF USING AN AGENT THAT IS NOT THE DEFAULT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2763391c-f37e-464d-b14e-556e9e95d0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(CLUSTER_URL, API_TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81130477-0c7d-4dd0-88cf-3d39f96d8079",
   "metadata": {},
   "source": [
    "## **Create a Project**\n",
    "\n",
    "Below, create a project to store this and other future adversarial robustness stress test run results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72059347",
   "metadata": {},
   "outputs": [],
   "source": [
    "description = (\n",
    "    \"Evaluate the robustness of text classification models\"\n",
    "    \" against adversarial attacks. Demonstration uses the\"\n",
    "    \" SST-2 dataset (https://huggingface.co/datasets/sst2)\"\n",
    "    \" and a fine-tuned version of the DistilBERT model\"\n",
    "    \" (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\"\n",
    ")\n",
    "project = client.create_project(\n",
    "    name=\"NLP Adversarial Robustness Demo\", \n",
    "    description=description,\n",
    "    model_task=\"MODEL_TASK_MULTICLASS_CLASSIFICATION\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a10ae5-cf42-4c0e-b8fa-741488a9bb86",
   "metadata": {},
   "source": [
    "## **Register Model and Datasets**\n",
    "\n",
    "Next, we use datasets (Stanford Sentiment Treebank) and model (DistilBERT) from huggingface, as described abov, and register those with RIME."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1994b6-d07c-4f7b-bfa7-0e06585f3f9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "dt = str(datetime.now())\n",
    "model_id = project.register_model(\n",
    "    f'model_{dt}',\n",
    "    model_config={\n",
    "        \"hugging_face\": {\n",
    "            \"model_uri\": \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "        }\n",
    "    },\n",
    "    agent_id=AGENT_ID\n",
    ")\n",
    "def _register_dataset(split_name):\n",
    "    data_info = {\n",
    "        \"connection_info\": {\n",
    "            \"hugging_face\": {\n",
    "                \"dataset_uri\": \"sst2\",\n",
    "                \"split_name\": split_name,\n",
    "            },\n",
    "        },\n",
    "        \"data_params\": {\n",
    "            \"label_col\": \"label\",\n",
    "            \"text_features\": [\"sentence\"],\n",
    "            \"sample\": True,\n",
    "            \"nrows\": 100\n",
    "        },\n",
    "    }\n",
    "    return project.register_dataset(f'{split_name}_datset_{dt}', data_info, agent_id=AGENT_ID)\n",
    "\n",
    "\n",
    "ref_dataset_id = _register_dataset(\"train\")\n",
    "eval_dataset_id = _register_dataset(\"validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3658ba7-783e-4062-a377-adbc906110b5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## **Start Stress Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ec5f73-b803-4a55-8150-ea57b2096669",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stress_test_config = {\n",
    "    \"run_name\": \"DistilBERT Adversarial Robustness\",\n",
    "    \"data_info\": {\n",
    "        \"ref_dataset_id\": ref_dataset_id,\n",
    "        \"eval_dataset_id\": eval_dataset_id,\n",
    "    },\n",
    "    \"model_id\": model_id,\n",
    "    \"categories\": [\n",
    "        \"TEST_CATEGORY_TYPE_ADVERSARIAL\",\n",
    "        \"TEST_CATEGORY_TYPE_SUBSET_PERFORMANCE\",\n",
    "        \"TEST_CATEGORY_TYPE_TRANSFORMATIONS\",\n",
    "        \"TEST_CATEGORY_TYPE_BIAS_AND_FAIRNESS\",\n",
    "        \"TEST_CATEGORY_TYPE_DATA_CLEANLINESS\"\n",
    "    ],\n",
    "    \"test_suite_config\": {\n",
    "        \"global_exclude_columns\": [\"idx\"]\n",
    "    },\n",
    "}\n",
    "stress_job = client.start_stress_test(\n",
    "    stress_test_config, project.project_id, agent_id=AGENT_ID\n",
    ")\n",
    "stress_job.get_status(verbose=True, wait_until_finish=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf6f351-719c-4f35-bddd-60bcb4eee8fd",
   "metadata": {},
   "source": [
    "## **Review Adversarial Stress Test Run**\n",
    "\n",
    "Now that the test run is complete, we can check out the results in the RIME web interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9acd72-b9c6-48c5-a30f-2fdc9cba89b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_run = stress_job.get_test_run()\n",
    "test_run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ddb22ae-f29d-4520-ae41-c30d04682210",
   "metadata": {
    "tags": []
   },
   "source": [
    "## **Query Results**\n",
    "\n",
    "Alternatively, we can query the test case results to identify model vulnerabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6684384-d58c-45ac-b4f8-46ee03453356",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = test_run.get_result_df()\n",
    "result_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19b26bb-8b21-466a-8ee4-cab74e2fd2c6",
   "metadata": {},
   "source": [
    "**Test Severity**: Let's plot some of the results. First, let's check the severity distribution of attack tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3278b31f-40f7-44ba-8ebb-4bbd6fc3368a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set_theme(style=\"white\")\n",
    "\n",
    "severity_cols = [col for col in result_df.columns if 'severity_counts' in col.lower()]\n",
    "severity_counts = result_df[severity_cols].iloc[0]\n",
    "plt.pie(severity_counts, labels=severity_cols)\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2b3246-3af2-49dc-97f5-cd5ca681bdac",
   "metadata": {},
   "source": [
    "## **Reviewing Test Case Results**\n",
    "\n",
    "Next, let's look at the results by attack type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e8bb78-9125-418f-a344-8f7d2ac50ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cases_df = test_run.get_test_cases_df(show_test_case_metrics=True)\n",
    "test_cases_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ab4ad4-c4d1-4154-9fe4-87941aff633f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,10))\n",
    "test_type_pass_rates = {name: (batch_df['severity'] == 'SEVERITY_PASS').sum() / len(batch_df) for name, batch_df in test_cases_df.groupby(\"test_batch_type\")}\n",
    "sns.barplot(y=list(test_type_pass_rates.keys()), x=list(test_type_pass_rates.values()), orient='h')\n",
    "plt.xlabel('Pass Rate')\n",
    "plt.ylabel('Test Type')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb69128",
   "metadata": {},
   "source": [
    "You can also query certain test batch-level metrics, including the model's accuracy on the original and perturbed inputs, and the average number of queries for the attack algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889e196e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "col_name_map = {\n",
    "    \"test_name\": \"Test Name\",\n",
    "    \"PERFORMANCE_METRIC_VALUE:original_accuracy\": \"Original Accuracy\",\n",
    "    \"PERFORMANCE_METRIC_VALUE:perturbed_accuracy\": \"Perturbed Accuracy\",\n",
    "    \"ATTACK_DETAILS:avg_queries\": \"Average Number of Queries\",\n",
    "}\n",
    "\n",
    "def _all_col_names_in_summary_df(col_names, summary_df):\n",
    "    for col_name in col_names:\n",
    "        if col_name not in summary_df.index:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "test_batches = test_run.get_test_batches()\n",
    "all_summaries = []\n",
    "for batch in test_batches:\n",
    "    summary_df = batch.summary(show_batch_metrics=True)\n",
    "    test_name = summary_df['test_name']\n",
    "    if _all_col_names_in_summary_df(col_name_map.keys(), summary_df):\n",
    "        all_summaries.append(summary_df[list(col_name_map.keys())])\n",
    "metrics_df = pd.concat(all_summaries, axis=1).T\n",
    "metrics_df = metrics_df.rename(columns=col_name_map).set_index(\"Test Name\")\n",
    "metrics_df.sort_values(by=\"Perturbed Accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe66347-cf70-40e3-9fe4-f82e463f5696",
   "metadata": {},
   "source": [
    "It's evident that while this model is fairly robust to simple transformation-style augmentations, it fails to withstand some character-level evolutionary attacks, indicating that additional data augmentation and/or a data sanitation pipeline should be applied before this model goes into production! One way to add additional augmented data to your training problem is through querying the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1a67ba-8fed-4046-b923-2ab3fe99916a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def filter_rows(text_series: pd.Series, label_series: pd.Series) -> pd.DataFrame:\n",
    "    filter_indices = ~text_series.isna()\n",
    "    return pd.DataFrame({'Augmented': text_series[filter_indices], \"Labels\": label_series[filter_indices]})\n",
    "\n",
    "failed_df = test_cases_df[test_cases_df['severity'] == 'SEVERITY_ALERT']\n",
    "\n",
    "# attacks examples\n",
    "perturbed_text_col =  [col for col in test_cases_df.columns if col.endswith('perturbed_sentence')][0] \n",
    "class_col = [col for col in test_cases_df.columns if col.endswith('original_class')][0]\n",
    "perturbed_df = filter_rows(failed_df[perturbed_text_col], failed_df[class_col])\n",
    "\n",
    "perturbed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e32bac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "ca72df3b9ba417119a386bc7f6836e81c78349bc450cdbaf3afafb90bdf8ed1f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
